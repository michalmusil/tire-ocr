{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"AiPipeline AiPipeline is an extendable and scalable platform for creating and running custom pipelines made as a part of diploma thesis project. It enables running complex, multi-step pipelines at a large scale both for single input tasks and large, statistics-driven datasets. At the same time, it provides a simple interface for extending the platform functionality by adding new, custom procedures for handling almost any use-case you can think of. How does it work AiPipeline runs as a microservice oriented platform consisting of one runner, which orchestrates a network of infinitely scalable nodes. Each node then provides a set of procedures, which accept an input with a given scheme and return an output with a (not necessarily) different scheme. Using the OrchestrationRunner Api, you can chain these node procedures together, each procedure's output providing an input to the next one, thus creating a complex data pipeline. You can read more about the inner workings of the AiPipeline on the Architecture page","title":"Home"},{"location":"#aipipeline","text":"AiPipeline is an extendable and scalable platform for creating and running custom pipelines made as a part of diploma thesis project. It enables running complex, multi-step pipelines at a large scale both for single input tasks and large, statistics-driven datasets. At the same time, it provides a simple interface for extending the platform functionality by adding new, custom procedures for handling almost any use-case you can think of.","title":"AiPipeline"},{"location":"#how-does-it-work","text":"AiPipeline runs as a microservice oriented platform consisting of one runner, which orchestrates a network of infinitely scalable nodes. Each node then provides a set of procedures, which accept an input with a given scheme and return an output with a (not necessarily) different scheme. Using the OrchestrationRunner Api, you can chain these node procedures together, each procedure's output providing an input to the next one, thus creating a complex data pipeline. You can read more about the inner workings of the AiPipeline on the Architecture page","title":"How does it work"},{"location":"ap-scheme/","text":"Ap scheme The ApScheme is a set of predefined JSON structures - ApElements , used to represent data types within the AiPipeline platform. This universal schema allows the Orchestration Runner and Nodes to communicate seamlessly and ensures pipeline compatibility. The ApScheme is essential for: Node Communication: Defining the input and output data schemes for node procedures. User Input: Constructing initial pipeline inputs in a universally readable format. Pipeline Validation: Allowing the Orchestration Runner to automatically validate pipeline connections. Extensibility: Providing a universal, human-readable, and JSON-parsable structure that can be easily extended. You will encounter ApSchemes when: Discovering Nodes: Procedure input and output are defined using ApScheme. Running Pipelines: The initial input must be a valid ApScheme instance compatible with the first procedure's input. Analyzing Results: Successful pipeline results are stored in the ApScheme format. ApElement Structure All ApElements are JSON objects at their root. While each element has its own set of properties, they all share one mandatory key: type . This property acts as a type discriminator and must always contain the correct string identifier for the respective element (e.g., \"type\": \"ApString\" ). ApElement Overview The following is a list of all available ApElements with notes on their usage and interpretation. 1. ApBool Represents a simple boolean value ( true / false ). The value is stored in the value property. In a procedure I/O scheme definition, the default value is false . Example: { \"type\": \"ApBool\", \"value\": true } 2. ApString Represents a string of characters. The value is stored in the value property. In a procedure I/O scheme definition, the default value is an empty string ( \"\" ). Example: { \"type\": \"ApString\", \"value\": \"my own string\" } 3. ApInt Represents an integer value. The value is stored in the value property. In a procedure I/O scheme definition, the default value is 0 . Example: { \"type\": \"ApInt\", \"value\": 455 } 4. ApDecimal Represents a high-precision floating-point number. The value is stored in the value property. In a procedure I/O scheme definition, the default value is 0 . Example: { \"type\": \"ApDecimal\", \"value\": 3.00123345004 } 5. ApDateTime Represents a date and time value encoded in the ISO 8601 standard. The value is stored in the value property. In a procedure I/O scheme definition, the default value is the current UTC date and time. Example: { \"type\": \"ApDateTime\", \"value\": \"2024-01-24T06:09:19.384957Z\" } 6. ApEnum Represents an enumeration with a predefined set of string values. It has two specific properties: supportedCases : An array of strings defining all possible valid values for the enumeration. This property is used only in scheme definitions. value : A string representing one of the supportedCases. When defining a procedure scheme, value is an empty string and supportedCases is populated. When providing a pipeline input, supportedCases is optional, but value must match one of the cases from the procedure's scheme input definition. Example in procedure scheme definition: { \"type\": \"ApEnum\", \"value\": \"\", \"supportedCases\": [ \"GoogleGemini\", \"MistralPixtral\", \"OpenAiGpt\", \"GoogleCloudVision\", \"AzureAiVision\" ] } Example in pipeline input: { \"type\": \"ApEnum\", \"value\": \"GoogleGemini\" } 6. ApFile Represents a file stored in the central FileService. This is the only supported method for passing files between nodes. It has three specific properties: id : The GUID of the file in the FileService. contentType : The MIME type of the file (e.g., image/jpeg ). supportedContentTypes : An array of strings defining the MIME types a procedure input can accept. This property is used only in scheme definitions. In a procedure scheme definition, contentType is an empty string, and id is an empty GUID ( 00000000-0000-0000-0000-000000000000 ). When providing a pipeline input, you must supply a valid id and contentType that matches a supportedContentTypes from the procedure's scheme. Example in procedure scheme definition: { \"type\": \"ApFile\", \"id\": \"00000000-0000-0000-0000-000000000000\", \"contentType\": \"\", \"supportedContentTypes\": [\"image/jpeg\", \"image/png\", \"image/webp\"] } Example in pipeline input: { \"type\": \"ApFile\", \"id\": \"e9ecec8e-bf34-409e-80e4-7cd1ae651c81\", \"contentType\": \"image/jpeg\" } 6. ApList Represents a list of values of a common type. The list can contain any other ApElement, including nested ApList and ApObject elements. It has one specific property: items : A JSON array containing the ApElements in the list. In a procedure scheme definition, the items array should contain exactly one element, which serves as a template for the list's type. In a pipeline input, all items within the list must match this template's ApElement type. Example in procedure scheme definition: { \"type\": \"ApList\", \"items\": [ { \"type\": \"ApString\", \"value\": \"\" } ] } Example in pipeline input: { \"type\": \"ApList\", \"items\": [ { \"type\": \"ApString\", \"value\": \"My value item 1\" }, { \"type\": \"ApString\", \"value\": \"My value item 2\" } ] } 7. ApObject Represents an object with key-value pairs. Keys are unique string identifiers, and values are any other ApElement. ApObjects can be arbitrarily nested. It has two specific properties: properties : A JSON object holding the inner properties of the ApObject. Keys are unique strings, and values are ApElements. nonRequiredProperties : An array of strings used in input schemes to define optional properties. For two ApObject schemes to be compatible (e.g., a procedure output and a subsequent procedure input), the output object must contain all required keys from the input object, with matching ApElement types. Keys listed in nonRequiredProperties are not checked during this validation. Example in procedure scheme definition: { \"type\": \"ApObject\", \"properties\": { \"detectorType\": { \"type\": \"ApEnum\", \"value\": \"\", \"supportedCases\": [ \"GoogleGemini\", \"MistralPixtral\", \"OpenAiGpt\", \"GoogleCloudVision\", \"AzureAiVision\" ] }, \"image\": { \"type\": \"ApFile\", \"id\": \"00000000-0000-0000-0000-000000000000\", \"contentType\": \"\", \"supportedContentTypes\": [\"image/jpeg\", \"image/png\", \"image/webp\"] } }, \"nonRequiredProperties\": [\"detectorType\"] } Example in pipeline input: { \"type\": \"ApObject\", \"properties\": { \"detectorType\": { \"type\": \"ApEnum\", \"value\": \"MistralPixtral\" }, \"image\": { \"type\": \"ApFile\", \"id\": \"1eda3a21-bf66-4abd-9bfb-15afc1691eed\", \"contentType\": \"image/webp\" } } } Note: due to mention of detectorType in nonRequiredProperties , this would also be a valid input: { \"type\": \"ApObject\", \"properties\": { \"image\": { \"type\": \"ApFile\", \"id\": \"1eda3a21-bf66-4abd-9bfb-15afc1691eed\", \"contentType\": \"image/webp\" } } }","title":"Ap scheme"},{"location":"ap-scheme/#ap-scheme","text":"The ApScheme is a set of predefined JSON structures - ApElements , used to represent data types within the AiPipeline platform. This universal schema allows the Orchestration Runner and Nodes to communicate seamlessly and ensures pipeline compatibility. The ApScheme is essential for: Node Communication: Defining the input and output data schemes for node procedures. User Input: Constructing initial pipeline inputs in a universally readable format. Pipeline Validation: Allowing the Orchestration Runner to automatically validate pipeline connections. Extensibility: Providing a universal, human-readable, and JSON-parsable structure that can be easily extended. You will encounter ApSchemes when: Discovering Nodes: Procedure input and output are defined using ApScheme. Running Pipelines: The initial input must be a valid ApScheme instance compatible with the first procedure's input. Analyzing Results: Successful pipeline results are stored in the ApScheme format.","title":"Ap scheme"},{"location":"ap-scheme/#apelement-structure","text":"All ApElements are JSON objects at their root. While each element has its own set of properties, they all share one mandatory key: type . This property acts as a type discriminator and must always contain the correct string identifier for the respective element (e.g., \"type\": \"ApString\" ).","title":"ApElement Structure"},{"location":"ap-scheme/#apelement-overview","text":"The following is a list of all available ApElements with notes on their usage and interpretation.","title":"ApElement Overview"},{"location":"ap-scheme/#1-apbool","text":"Represents a simple boolean value ( true / false ). The value is stored in the value property. In a procedure I/O scheme definition, the default value is false . Example: { \"type\": \"ApBool\", \"value\": true }","title":"1. ApBool"},{"location":"ap-scheme/#2-apstring","text":"Represents a string of characters. The value is stored in the value property. In a procedure I/O scheme definition, the default value is an empty string ( \"\" ). Example: { \"type\": \"ApString\", \"value\": \"my own string\" }","title":"2. ApString"},{"location":"ap-scheme/#3-apint","text":"Represents an integer value. The value is stored in the value property. In a procedure I/O scheme definition, the default value is 0 . Example: { \"type\": \"ApInt\", \"value\": 455 }","title":"3. ApInt"},{"location":"ap-scheme/#4-apdecimal","text":"Represents a high-precision floating-point number. The value is stored in the value property. In a procedure I/O scheme definition, the default value is 0 . Example: { \"type\": \"ApDecimal\", \"value\": 3.00123345004 }","title":"4. ApDecimal"},{"location":"ap-scheme/#5-apdatetime","text":"Represents a date and time value encoded in the ISO 8601 standard. The value is stored in the value property. In a procedure I/O scheme definition, the default value is the current UTC date and time. Example: { \"type\": \"ApDateTime\", \"value\": \"2024-01-24T06:09:19.384957Z\" }","title":"5. ApDateTime"},{"location":"ap-scheme/#6-apenum","text":"Represents an enumeration with a predefined set of string values. It has two specific properties: supportedCases : An array of strings defining all possible valid values for the enumeration. This property is used only in scheme definitions. value : A string representing one of the supportedCases. When defining a procedure scheme, value is an empty string and supportedCases is populated. When providing a pipeline input, supportedCases is optional, but value must match one of the cases from the procedure's scheme input definition. Example in procedure scheme definition: { \"type\": \"ApEnum\", \"value\": \"\", \"supportedCases\": [ \"GoogleGemini\", \"MistralPixtral\", \"OpenAiGpt\", \"GoogleCloudVision\", \"AzureAiVision\" ] } Example in pipeline input: { \"type\": \"ApEnum\", \"value\": \"GoogleGemini\" }","title":"6. ApEnum"},{"location":"ap-scheme/#6-apfile","text":"Represents a file stored in the central FileService. This is the only supported method for passing files between nodes. It has three specific properties: id : The GUID of the file in the FileService. contentType : The MIME type of the file (e.g., image/jpeg ). supportedContentTypes : An array of strings defining the MIME types a procedure input can accept. This property is used only in scheme definitions. In a procedure scheme definition, contentType is an empty string, and id is an empty GUID ( 00000000-0000-0000-0000-000000000000 ). When providing a pipeline input, you must supply a valid id and contentType that matches a supportedContentTypes from the procedure's scheme. Example in procedure scheme definition: { \"type\": \"ApFile\", \"id\": \"00000000-0000-0000-0000-000000000000\", \"contentType\": \"\", \"supportedContentTypes\": [\"image/jpeg\", \"image/png\", \"image/webp\"] } Example in pipeline input: { \"type\": \"ApFile\", \"id\": \"e9ecec8e-bf34-409e-80e4-7cd1ae651c81\", \"contentType\": \"image/jpeg\" }","title":"6. ApFile"},{"location":"ap-scheme/#6-aplist","text":"Represents a list of values of a common type. The list can contain any other ApElement, including nested ApList and ApObject elements. It has one specific property: items : A JSON array containing the ApElements in the list. In a procedure scheme definition, the items array should contain exactly one element, which serves as a template for the list's type. In a pipeline input, all items within the list must match this template's ApElement type. Example in procedure scheme definition: { \"type\": \"ApList\", \"items\": [ { \"type\": \"ApString\", \"value\": \"\" } ] } Example in pipeline input: { \"type\": \"ApList\", \"items\": [ { \"type\": \"ApString\", \"value\": \"My value item 1\" }, { \"type\": \"ApString\", \"value\": \"My value item 2\" } ] }","title":"6. ApList"},{"location":"ap-scheme/#7-apobject","text":"Represents an object with key-value pairs. Keys are unique string identifiers, and values are any other ApElement. ApObjects can be arbitrarily nested. It has two specific properties: properties : A JSON object holding the inner properties of the ApObject. Keys are unique strings, and values are ApElements. nonRequiredProperties : An array of strings used in input schemes to define optional properties. For two ApObject schemes to be compatible (e.g., a procedure output and a subsequent procedure input), the output object must contain all required keys from the input object, with matching ApElement types. Keys listed in nonRequiredProperties are not checked during this validation. Example in procedure scheme definition: { \"type\": \"ApObject\", \"properties\": { \"detectorType\": { \"type\": \"ApEnum\", \"value\": \"\", \"supportedCases\": [ \"GoogleGemini\", \"MistralPixtral\", \"OpenAiGpt\", \"GoogleCloudVision\", \"AzureAiVision\" ] }, \"image\": { \"type\": \"ApFile\", \"id\": \"00000000-0000-0000-0000-000000000000\", \"contentType\": \"\", \"supportedContentTypes\": [\"image/jpeg\", \"image/png\", \"image/webp\"] } }, \"nonRequiredProperties\": [\"detectorType\"] } Example in pipeline input: { \"type\": \"ApObject\", \"properties\": { \"detectorType\": { \"type\": \"ApEnum\", \"value\": \"MistralPixtral\" }, \"image\": { \"type\": \"ApFile\", \"id\": \"1eda3a21-bf66-4abd-9bfb-15afc1691eed\", \"contentType\": \"image/webp\" } } } Note: due to mention of detectorType in nonRequiredProperties , this would also be a valid input: { \"type\": \"ApObject\", \"properties\": { \"image\": { \"type\": \"ApFile\", \"id\": \"1eda3a21-bf66-4abd-9bfb-15afc1691eed\", \"contentType\": \"image/webp\" } } }","title":"7. ApObject"},{"location":"architecture/","text":"AiPipeline Platform Architecture Overview The AiPipeline platform provides a scalable solution for complex data-processing pipelines through node-to-node communication. The system is built with a decoupled architecture, allowing each node to be deployed independently in either cloud or on-premise environments. The platform is composed of three core components: the Orchestration Runner, the File Service, and the individual Nodes. All core components are implemented in .NET 8 (with an exception of Nodes, which may be extended and implemented using any platoform) and follow Clean Architecture, CQRS, and microservice principles. This layered approach ensures a clear separation of concerns between the domain, application, infrastructure, and presentation layers. Communication Protocols To ensure smooth and efficient operation, the AiPipeline platform utilizes different communication technologies tailored to each specific task. User-to-System : The Orchestration Runner exposes a RESTful API, serving as the single public entry point for users to interact with the platform. Inter-component Communication (Runner-to-Node & Node-to-Node) : RabbitMQ is used as a message broker to facilitate the distribution and orchestration of pipelines. The runner initiates a pipeline by sending a message to the first node. Each subsequent node processes the message, sends the result to the next node in the pipeline, and sends a completion notification back to the runner. File Handling (Node-to-FileService & Runner-to-FileService) : For server-to-server communication with the File Service, gRPC is the protocol of choice. Its minimal overhead and high efficiency make it ideal for the transfer of large file data. Core Components 1. Orchestration Runner (AiPipeline.Orchestration.Runner) The Orchestration Runner is the central nervous system of the platform. It's a web service that provides the only public-facing API, allowing users to: Initiate and run pipelines. Analyze pipeline results. Manage user accounts and pipeline files. Its primary responsibilities include pipeline creation, validation, and mapping the correct sequence of nodes for a given process. All other platform components, including the nodes and the File Service, are hosted privately and are not publicly exposed. 2. Nodes (AiPipeline.YourNodeName) A node is an independent service integrated into the AiPipeline platform by implementing a specific set of interfaces (described in Create your own node ). Each node can have multiple procedures, each with a defined input and output scheme. Users can chain these procedures together using the Orchestration Runner to create complex, long-running pipelines. For scalability, the same type of node (same identifier, procedures and interface) can be deployed as multiple duplicates. The Orchestration Runner automatically distributes the workload of running pipelines evenly among these duplicates, which is crucial for handling parallel processing or computationally intensive tasks. 3. File Service (AiPipeline.Orchestration.FileService) The File Service provides a unified API for nodes to manage files (e.g., images, documents, videos) used within pipelines. It is a private service, accessible only by other components within the platform deployment. This ensures secure handling of sensitive data. Important Note : Only files residing within the File Service can be processed by pipelines. Users can manage their files through the Orchestration Runner's public API. The File Service itself is a standalone .NET service that uses a PostgreSQL database to track file records and an S3-compatible storage solution (MinIO) to store the actual file data. Due to its server-to-server communication pattern and focus on large data transfers, it exclusively uses a gRPC API for efficiency.","title":"Architecture"},{"location":"architecture/#aipipeline-platform-architecture-overview","text":"The AiPipeline platform provides a scalable solution for complex data-processing pipelines through node-to-node communication. The system is built with a decoupled architecture, allowing each node to be deployed independently in either cloud or on-premise environments. The platform is composed of three core components: the Orchestration Runner, the File Service, and the individual Nodes. All core components are implemented in .NET 8 (with an exception of Nodes, which may be extended and implemented using any platoform) and follow Clean Architecture, CQRS, and microservice principles. This layered approach ensures a clear separation of concerns between the domain, application, infrastructure, and presentation layers.","title":"AiPipeline Platform Architecture Overview"},{"location":"architecture/#communication-protocols","text":"To ensure smooth and efficient operation, the AiPipeline platform utilizes different communication technologies tailored to each specific task. User-to-System : The Orchestration Runner exposes a RESTful API, serving as the single public entry point for users to interact with the platform. Inter-component Communication (Runner-to-Node & Node-to-Node) : RabbitMQ is used as a message broker to facilitate the distribution and orchestration of pipelines. The runner initiates a pipeline by sending a message to the first node. Each subsequent node processes the message, sends the result to the next node in the pipeline, and sends a completion notification back to the runner. File Handling (Node-to-FileService & Runner-to-FileService) : For server-to-server communication with the File Service, gRPC is the protocol of choice. Its minimal overhead and high efficiency make it ideal for the transfer of large file data.","title":"Communication Protocols"},{"location":"architecture/#core-components","text":"","title":"Core Components"},{"location":"architecture/#1-orchestration-runner-aipipelineorchestrationrunner","text":"The Orchestration Runner is the central nervous system of the platform. It's a web service that provides the only public-facing API, allowing users to: Initiate and run pipelines. Analyze pipeline results. Manage user accounts and pipeline files. Its primary responsibilities include pipeline creation, validation, and mapping the correct sequence of nodes for a given process. All other platform components, including the nodes and the File Service, are hosted privately and are not publicly exposed.","title":"1. Orchestration Runner (AiPipeline.Orchestration.Runner)"},{"location":"architecture/#2-nodes-aipipelineyournodename","text":"A node is an independent service integrated into the AiPipeline platform by implementing a specific set of interfaces (described in Create your own node ). Each node can have multiple procedures, each with a defined input and output scheme. Users can chain these procedures together using the Orchestration Runner to create complex, long-running pipelines. For scalability, the same type of node (same identifier, procedures and interface) can be deployed as multiple duplicates. The Orchestration Runner automatically distributes the workload of running pipelines evenly among these duplicates, which is crucial for handling parallel processing or computationally intensive tasks.","title":"2. Nodes (AiPipeline.YourNodeName)"},{"location":"architecture/#3-file-service-aipipelineorchestrationfileservice","text":"The File Service provides a unified API for nodes to manage files (e.g., images, documents, videos) used within pipelines. It is a private service, accessible only by other components within the platform deployment. This ensures secure handling of sensitive data. Important Note : Only files residing within the File Service can be processed by pipelines. Users can manage their files through the Orchestration Runner's public API. The File Service itself is a standalone .NET service that uses a PostgreSQL database to track file records and an S3-compatible storage solution (MinIO) to store the actual file data. Due to its server-to-server communication pattern and focus on large data transfers, it exclusively uses a gRPC API for efficiency.","title":"3. File Service (AiPipeline.Orchestration.FileService)"},{"location":"license/","text":"License: CC BY-NC-SA Attribution-NonCommercial-ShareAlike 4.0 International ======================================================================= Creative Commons Corporation (\"Creative Commons\") is not a law firm and does not provide legal services or legal advice. Distribution of Creative Commons public licenses does not create a lawyer-client or other relationship. Creative Commons makes its licenses and related information available on an \"as-is\" basis. Creative Commons gives no warranties regarding its licenses, any material licensed under their terms and conditions, or any related information. Creative Commons disclaims all liability for damages resulting from their use to the fullest extent possible. Using Creative Commons Public Licenses Creative Commons public licenses provide a standard set of terms and conditions that creators and other rights holders may use to share original works of authorship and other material subject to copyright and certain other rights specified in the public license below. The following considerations are for informational purposes only, are not exhaustive, and do not form part of our licenses. Considerations for licensors: Our public licenses are intended for use by those authorized to give the public permission to use material in ways otherwise restricted by copyright and certain other rights. Our licenses are irrevocable. Licensors should read and understand the terms and conditions of the license they choose before applying it. Licensors should also secure all rights necessary before applying our licenses so that the public can reuse the material as expected. Licensors should clearly mark any material not subject to the license. This includes other CC- licensed material, or material used under an exception or limitation to copyright. More considerations for licensors: wiki.creativecommons.org/Considerations_for_licensors Considerations for the public: By using one of our public licenses, a licensor grants the public permission to use the licensed material under specified terms and conditions. If the licensor's permission is not necessary for any reason--for example, because of any applicable exception or limitation to copyright--then that use is not regulated by the license. Our licenses grant only permissions under copyright and certain other rights that a licensor has authority to grant. Use of the licensed material may still be restricted for other reasons, including because others have copyright or other rights in the material. A licensor may make special requests, such as asking that all changes be marked or described. Although not required by our licenses, you are encouraged to respect those requests where reasonable. More considerations for the public: wiki.creativecommons.org/Considerations_for_licensees ======================================================================= Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International Public License By exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International Public License (\"Public License\"). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions. Section 1 -- Definitions. a. Adapted Material means material subject to Copyright and Similar Rights that is derived from or based upon the Licensed Material and in which the Licensed Material is translated, altered, arranged, transformed, or otherwise modified in a manner requiring permission under the Copyright and Similar Rights held by the Licensor. For purposes of this Public License, where the Licensed Material is a musical work, performance, or sound recording, Adapted Material is always produced where the Licensed Material is synched in timed relation with a moving image. b. Adapter's License means the license You apply to Your Copyright and Similar Rights in Your contributions to Adapted Material in accordance with the terms and conditions of this Public License. c. BY-NC-SA Compatible License means a license listed at creativecommons.org/compatiblelicenses, approved by Creative Commons as essentially the equivalent of this Public License. d. Copyright and Similar Rights means copyright and/or similar rights closely related to copyright including, without limitation, performance, broadcast, sound recording, and Sui Generis Database Rights, without regard to how the rights are labeled or categorized. For purposes of this Public License, the rights specified in Section 2(b)(1)-(2) are not Copyright and Similar Rights. e. Effective Technological Measures means those measures that, in the absence of proper authority, may not be circumvented under laws fulfilling obligations under Article 11 of the WIPO Copyright Treaty adopted on December 20, 1996, and/or similar international agreements. f. Exceptions and Limitations means fair use, fair dealing, and/or any other exception or limitation to Copyright and Similar Rights that applies to Your use of the Licensed Material. g. License Elements means the license attributes listed in the name of a Creative Commons Public License. The License Elements of this Public License are Attribution, NonCommercial, and ShareAlike. h. Licensed Material means the artistic or literary work, database, or other material to which the Licensor applied this Public License. i. Licensed Rights means the rights granted to You subject to the terms and conditions of this Public License, which are limited to all Copyright and Similar Rights that apply to Your use of the Licensed Material and that the Licensor has authority to license. j. Licensor means the individual(s) or entity(ies) granting rights under this Public License. k. NonCommercial means not primarily intended for or directed towards commercial advantage or monetary compensation. For purposes of this Public License, the exchange of the Licensed Material for other material subject to Copyright and Similar Rights by digital file-sharing or similar means is NonCommercial provided there is no payment of monetary compensation in connection with the exchange. l. Share means to provide material to the public by any means or process that requires permission under the Licensed Rights, such as reproduction, public display, public performance, distribution, dissemination, communication, or importation, and to make material available to the public including in ways that members of the public may access the material from a place and at a time individually chosen by them. m. Sui Generis Database Rights means rights other than copyright resulting from Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases, as amended and/or succeeded, as well as other essentially equivalent rights anywhere in the world. n. You means the individual or entity exercising the Licensed Rights under this Public License. Your has a corresponding meaning. Section 2 -- Scope. a. License grant. 1. Subject to the terms and conditions of this Public License, the Licensor hereby grants You a worldwide, royalty-free, non-sublicensable, non-exclusive, irrevocable license to exercise the Licensed Rights in the Licensed Material to: a. reproduce and Share the Licensed Material, in whole or in part, for NonCommercial purposes only; and b. produce, reproduce, and Share Adapted Material for NonCommercial purposes only. 2. Exceptions and Limitations. For the avoidance of doubt, where Exceptions and Limitations apply to Your use, this Public License does not apply, and You do not need to comply with its terms and conditions. 3. Term. The term of this Public License is specified in Section 6(a). 4. Media and formats; technical modifications allowed. The Licensor authorizes You to exercise the Licensed Rights in all media and formats whether now known or hereafter created, and to make technical modifications necessary to do so. The Licensor waives and/or agrees not to assert any right or authority to forbid You from making technical modifications necessary to exercise the Licensed Rights, including technical modifications necessary to circumvent Effective Technological Measures. For purposes of this Public License, simply making modifications authorized by this Section 2(a) (4) never produces Adapted Material. 5. Downstream recipients. a. Offer from the Licensor -- Licensed Material. Every recipient of the Licensed Material automatically receives an offer from the Licensor to exercise the Licensed Rights under the terms and conditions of this Public License. b. Additional offer from the Licensor -- Adapted Material. Every recipient of Adapted Material from You automatically receives an offer from the Licensor to exercise the Licensed Rights in the Adapted Material under the conditions of the Adapter's License You apply. c. No downstream restrictions. You may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, the Licensed Material if doing so restricts exercise of the Licensed Rights by any recipient of the Licensed Material. 6. No endorsement. Nothing in this Public License constitutes or may be construed as permission to assert or imply that You are, or that Your use of the Licensed Material is, connected with, or sponsored, endorsed, or granted official status by, the Licensor or others designated to receive attribution as provided in Section 3(a)(1)(A)(i). b. Other rights. 1. Moral rights, such as the right of integrity, are not licensed under this Public License, nor are publicity, privacy, and/or other similar personality rights; however, to the extent possible, the Licensor waives and/or agrees not to assert any such rights held by the Licensor to the limited extent necessary to allow You to exercise the Licensed Rights, but not otherwise. 2. Patent and trademark rights are not licensed under this Public License. 3. To the extent possible, the Licensor waives any right to collect royalties from You for the exercise of the Licensed Rights, whether directly or through a collecting society under any voluntary or waivable statutory or compulsory licensing scheme. In all other cases the Licensor expressly reserves any right to collect such royalties, including when the Licensed Material is used other than for NonCommercial purposes. Section 3 -- License Conditions. Your exercise of the Licensed Rights is expressly made subject to the following conditions. a. Attribution. 1. If You Share the Licensed Material (including in modified form), You must: a. retain the following if it is supplied by the Licensor with the Licensed Material: i. identification of the creator(s) of the Licensed Material and any others designated to receive attribution, in any reasonable manner requested by the Licensor (including by pseudonym if designated); ii. a copyright notice; iii. a notice that refers to this Public License; iv. a notice that refers to the disclaimer of warranties; v. a URI or hyperlink to the Licensed Material to the extent reasonably practicable; b. indicate if You modified the Licensed Material and retain an indication of any previous modifications; and c. indicate the Licensed Material is licensed under this Public License, and include the text of, or the URI or hyperlink to, this Public License. 2. You may satisfy the conditions in Section 3(a)(1) in any reasonable manner based on the medium, means, and context in which You Share the Licensed Material. For example, it may be reasonable to satisfy the conditions by providing a URI or hyperlink to a resource that includes the required information. 3. If requested by the Licensor, You must remove any of the information required by Section 3(a)(1)(A) to the extent reasonably practicable. b. ShareAlike. In addition to the conditions in Section 3(a), if You Share Adapted Material You produce, the following conditions also apply. 1. The Adapter's License You apply must be a Creative Commons license with the same License Elements, this version or later, or a BY-NC-SA Compatible License. 2. You must include the text of, or the URI or hyperlink to, the Adapter's License You apply. You may satisfy this condition in any reasonable manner based on the medium, means, and context in which You Share Adapted Material. 3. You may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, Adapted Material that restrict exercise of the rights granted under the Adapter's License You apply. Section 4 -- Sui Generis Database Rights. Where the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material: a. for the avoidance of doubt, Section 2(a)(1) grants You the right to extract, reuse, reproduce, and Share all or a substantial portion of the contents of the database for NonCommercial purposes only; b. if You include all or a substantial portion of the database contents in a database in which You have Sui Generis Database Rights, then the database in which You have Sui Generis Database Rights (but not its individual contents) is Adapted Material, including for purposes of Section 3(b); and c. You must comply with the conditions in Section 3(a) if You Share all or a substantial portion of the contents of the database. For the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights. Section 5 -- Disclaimer of Warranties and Limitation of Liability. a. UNLESS OTHERWISE SEPARATELY UNDERTAKEN BY THE LICENSOR, TO THE EXTENT POSSIBLE, THE LICENSOR OFFERS THE LICENSED MATERIAL AS-IS AND AS-AVAILABLE, AND MAKES NO REPRESENTATIONS OR WARRANTIES OF ANY KIND CONCERNING THE LICENSED MATERIAL, WHETHER EXPRESS, IMPLIED, STATUTORY, OR OTHER. THIS INCLUDES, WITHOUT LIMITATION, WARRANTIES OF TITLE, MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, NON-INFRINGEMENT, ABSENCE OF LATENT OR OTHER DEFECTS, ACCURACY, OR THE PRESENCE OR ABSENCE OF ERRORS, WHETHER OR NOT KNOWN OR DISCOVERABLE. WHERE DISCLAIMERS OF WARRANTIES ARE NOT ALLOWED IN FULL OR IN PART, THIS DISCLAIMER MAY NOT APPLY TO YOU. b. TO THE EXTENT POSSIBLE, IN NO EVENT WILL THE LICENSOR BE LIABLE TO YOU ON ANY LEGAL THEORY (INCLUDING, WITHOUT LIMITATION, NEGLIGENCE) OR OTHERWISE FOR ANY DIRECT, SPECIAL, INDIRECT, INCIDENTAL, CONSEQUENTIAL, PUNITIVE, EXEMPLARY, OR OTHER LOSSES, COSTS, EXPENSES, OR DAMAGES ARISING OUT OF THIS PUBLIC LICENSE OR USE OF THE LICENSED MATERIAL, EVEN IF THE LICENSOR HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH LOSSES, COSTS, EXPENSES, OR DAMAGES. WHERE A LIMITATION OF LIABILITY IS NOT ALLOWED IN FULL OR IN PART, THIS LIMITATION MAY NOT APPLY TO YOU. c. The disclaimer of warranties and limitation of liability provided above shall be interpreted in a manner that, to the extent possible, most closely approximates an absolute disclaimer and waiver of all liability. Section 6 -- Term and Termination. a. This Public License applies for the term of the Copyright and Similar Rights licensed here. However, if You fail to comply with this Public License, then Your rights under this Public License terminate automatically. b. Where Your right to use the Licensed Material has terminated under Section 6(a), it reinstates: 1. automatically as of the date the violation is cured, provided it is cured within 30 days of Your discovery of the violation; or 2. upon express reinstatement by the Licensor. For the avoidance of doubt, this Section 6(b) does not affect any right the Licensor may have to seek remedies for Your violations of this Public License. c. For the avoidance of doubt, the Licensor may also offer the Licensed Material under separate terms or conditions or stop distributing the Licensed Material at any time; however, doing so will not terminate this Public License. d. Sections 1, 5, 6, 7, and 8 survive termination of this Public License. Section 7 -- Other Terms and Conditions. a. The Licensor shall not be bound by any additional or different terms or conditions communicated by You unless expressly agreed. b. Any arrangements, understandings, or agreements regarding the Licensed Material not stated herein are separate from and independent of the terms and conditions of this Public License. Section 8 -- Interpretation. a. For the avoidance of doubt, this Public License does not, and shall not be interpreted to, reduce, limit, restrict, or impose conditions on any use of the Licensed Material that could lawfully be made without permission under this Public License. b. To the extent possible, if any provision of this Public License is deemed unenforceable, it shall be automatically reformed to the minimum extent necessary to make it enforceable. If the provision cannot be reformed, it shall be severed from this Public License without affecting the enforceability of the remaining terms and conditions. c. No term or condition of this Public License will be waived and no failure to comply consented to unless expressly agreed to by the Licensor. d. Nothing in this Public License constitutes or may be interpreted as a limitation upon, or waiver of, any privileges and immunities that apply to the Licensor or You, including from the legal processes of any jurisdiction or authority. ======================================================================= Creative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the \u201cLicensor.\u201d The text of the Creative Commons public licenses is dedicated to the public domain under the CC0 Public Domain Dedication. Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark \"Creative Commons\" or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses. Creative Commons may be contacted at creativecommons.org.","title":"License"},{"location":"license/#license-cc-by-nc-sa","text":"Attribution-NonCommercial-ShareAlike 4.0 International ======================================================================= Creative Commons Corporation (\"Creative Commons\") is not a law firm and does not provide legal services or legal advice. Distribution of Creative Commons public licenses does not create a lawyer-client or other relationship. Creative Commons makes its licenses and related information available on an \"as-is\" basis. Creative Commons gives no warranties regarding its licenses, any material licensed under their terms and conditions, or any related information. Creative Commons disclaims all liability for damages resulting from their use to the fullest extent possible. Using Creative Commons Public Licenses Creative Commons public licenses provide a standard set of terms and conditions that creators and other rights holders may use to share original works of authorship and other material subject to copyright and certain other rights specified in the public license below. The following considerations are for informational purposes only, are not exhaustive, and do not form part of our licenses. Considerations for licensors: Our public licenses are intended for use by those authorized to give the public permission to use material in ways otherwise restricted by copyright and certain other rights. Our licenses are irrevocable. Licensors should read and understand the terms and conditions of the license they choose before applying it. Licensors should also secure all rights necessary before applying our licenses so that the public can reuse the material as expected. Licensors should clearly mark any material not subject to the license. This includes other CC- licensed material, or material used under an exception or limitation to copyright. More considerations for licensors: wiki.creativecommons.org/Considerations_for_licensors Considerations for the public: By using one of our public licenses, a licensor grants the public permission to use the licensed material under specified terms and conditions. If the licensor's permission is not necessary for any reason--for example, because of any applicable exception or limitation to copyright--then that use is not regulated by the license. Our licenses grant only permissions under copyright and certain other rights that a licensor has authority to grant. Use of the licensed material may still be restricted for other reasons, including because others have copyright or other rights in the material. A licensor may make special requests, such as asking that all changes be marked or described. Although not required by our licenses, you are encouraged to respect those requests where reasonable. More considerations for the public: wiki.creativecommons.org/Considerations_for_licensees ======================================================================= Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International Public License By exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International Public License (\"Public License\"). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions. Section 1 -- Definitions. a. Adapted Material means material subject to Copyright and Similar Rights that is derived from or based upon the Licensed Material and in which the Licensed Material is translated, altered, arranged, transformed, or otherwise modified in a manner requiring permission under the Copyright and Similar Rights held by the Licensor. For purposes of this Public License, where the Licensed Material is a musical work, performance, or sound recording, Adapted Material is always produced where the Licensed Material is synched in timed relation with a moving image. b. Adapter's License means the license You apply to Your Copyright and Similar Rights in Your contributions to Adapted Material in accordance with the terms and conditions of this Public License. c. BY-NC-SA Compatible License means a license listed at creativecommons.org/compatiblelicenses, approved by Creative Commons as essentially the equivalent of this Public License. d. Copyright and Similar Rights means copyright and/or similar rights closely related to copyright including, without limitation, performance, broadcast, sound recording, and Sui Generis Database Rights, without regard to how the rights are labeled or categorized. For purposes of this Public License, the rights specified in Section 2(b)(1)-(2) are not Copyright and Similar Rights. e. Effective Technological Measures means those measures that, in the absence of proper authority, may not be circumvented under laws fulfilling obligations under Article 11 of the WIPO Copyright Treaty adopted on December 20, 1996, and/or similar international agreements. f. Exceptions and Limitations means fair use, fair dealing, and/or any other exception or limitation to Copyright and Similar Rights that applies to Your use of the Licensed Material. g. License Elements means the license attributes listed in the name of a Creative Commons Public License. The License Elements of this Public License are Attribution, NonCommercial, and ShareAlike. h. Licensed Material means the artistic or literary work, database, or other material to which the Licensor applied this Public License. i. Licensed Rights means the rights granted to You subject to the terms and conditions of this Public License, which are limited to all Copyright and Similar Rights that apply to Your use of the Licensed Material and that the Licensor has authority to license. j. Licensor means the individual(s) or entity(ies) granting rights under this Public License. k. NonCommercial means not primarily intended for or directed towards commercial advantage or monetary compensation. For purposes of this Public License, the exchange of the Licensed Material for other material subject to Copyright and Similar Rights by digital file-sharing or similar means is NonCommercial provided there is no payment of monetary compensation in connection with the exchange. l. Share means to provide material to the public by any means or process that requires permission under the Licensed Rights, such as reproduction, public display, public performance, distribution, dissemination, communication, or importation, and to make material available to the public including in ways that members of the public may access the material from a place and at a time individually chosen by them. m. Sui Generis Database Rights means rights other than copyright resulting from Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases, as amended and/or succeeded, as well as other essentially equivalent rights anywhere in the world. n. You means the individual or entity exercising the Licensed Rights under this Public License. Your has a corresponding meaning. Section 2 -- Scope. a. License grant. 1. Subject to the terms and conditions of this Public License, the Licensor hereby grants You a worldwide, royalty-free, non-sublicensable, non-exclusive, irrevocable license to exercise the Licensed Rights in the Licensed Material to: a. reproduce and Share the Licensed Material, in whole or in part, for NonCommercial purposes only; and b. produce, reproduce, and Share Adapted Material for NonCommercial purposes only. 2. Exceptions and Limitations. For the avoidance of doubt, where Exceptions and Limitations apply to Your use, this Public License does not apply, and You do not need to comply with its terms and conditions. 3. Term. The term of this Public License is specified in Section 6(a). 4. Media and formats; technical modifications allowed. The Licensor authorizes You to exercise the Licensed Rights in all media and formats whether now known or hereafter created, and to make technical modifications necessary to do so. The Licensor waives and/or agrees not to assert any right or authority to forbid You from making technical modifications necessary to exercise the Licensed Rights, including technical modifications necessary to circumvent Effective Technological Measures. For purposes of this Public License, simply making modifications authorized by this Section 2(a) (4) never produces Adapted Material. 5. Downstream recipients. a. Offer from the Licensor -- Licensed Material. Every recipient of the Licensed Material automatically receives an offer from the Licensor to exercise the Licensed Rights under the terms and conditions of this Public License. b. Additional offer from the Licensor -- Adapted Material. Every recipient of Adapted Material from You automatically receives an offer from the Licensor to exercise the Licensed Rights in the Adapted Material under the conditions of the Adapter's License You apply. c. No downstream restrictions. You may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, the Licensed Material if doing so restricts exercise of the Licensed Rights by any recipient of the Licensed Material. 6. No endorsement. Nothing in this Public License constitutes or may be construed as permission to assert or imply that You are, or that Your use of the Licensed Material is, connected with, or sponsored, endorsed, or granted official status by, the Licensor or others designated to receive attribution as provided in Section 3(a)(1)(A)(i). b. Other rights. 1. Moral rights, such as the right of integrity, are not licensed under this Public License, nor are publicity, privacy, and/or other similar personality rights; however, to the extent possible, the Licensor waives and/or agrees not to assert any such rights held by the Licensor to the limited extent necessary to allow You to exercise the Licensed Rights, but not otherwise. 2. Patent and trademark rights are not licensed under this Public License. 3. To the extent possible, the Licensor waives any right to collect royalties from You for the exercise of the Licensed Rights, whether directly or through a collecting society under any voluntary or waivable statutory or compulsory licensing scheme. In all other cases the Licensor expressly reserves any right to collect such royalties, including when the Licensed Material is used other than for NonCommercial purposes. Section 3 -- License Conditions. Your exercise of the Licensed Rights is expressly made subject to the following conditions. a. Attribution. 1. If You Share the Licensed Material (including in modified form), You must: a. retain the following if it is supplied by the Licensor with the Licensed Material: i. identification of the creator(s) of the Licensed Material and any others designated to receive attribution, in any reasonable manner requested by the Licensor (including by pseudonym if designated); ii. a copyright notice; iii. a notice that refers to this Public License; iv. a notice that refers to the disclaimer of warranties; v. a URI or hyperlink to the Licensed Material to the extent reasonably practicable; b. indicate if You modified the Licensed Material and retain an indication of any previous modifications; and c. indicate the Licensed Material is licensed under this Public License, and include the text of, or the URI or hyperlink to, this Public License. 2. You may satisfy the conditions in Section 3(a)(1) in any reasonable manner based on the medium, means, and context in which You Share the Licensed Material. For example, it may be reasonable to satisfy the conditions by providing a URI or hyperlink to a resource that includes the required information. 3. If requested by the Licensor, You must remove any of the information required by Section 3(a)(1)(A) to the extent reasonably practicable. b. ShareAlike. In addition to the conditions in Section 3(a), if You Share Adapted Material You produce, the following conditions also apply. 1. The Adapter's License You apply must be a Creative Commons license with the same License Elements, this version or later, or a BY-NC-SA Compatible License. 2. You must include the text of, or the URI or hyperlink to, the Adapter's License You apply. You may satisfy this condition in any reasonable manner based on the medium, means, and context in which You Share Adapted Material. 3. You may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, Adapted Material that restrict exercise of the rights granted under the Adapter's License You apply. Section 4 -- Sui Generis Database Rights. Where the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material: a. for the avoidance of doubt, Section 2(a)(1) grants You the right to extract, reuse, reproduce, and Share all or a substantial portion of the contents of the database for NonCommercial purposes only; b. if You include all or a substantial portion of the database contents in a database in which You have Sui Generis Database Rights, then the database in which You have Sui Generis Database Rights (but not its individual contents) is Adapted Material, including for purposes of Section 3(b); and c. You must comply with the conditions in Section 3(a) if You Share all or a substantial portion of the contents of the database. For the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights. Section 5 -- Disclaimer of Warranties and Limitation of Liability. a. UNLESS OTHERWISE SEPARATELY UNDERTAKEN BY THE LICENSOR, TO THE EXTENT POSSIBLE, THE LICENSOR OFFERS THE LICENSED MATERIAL AS-IS AND AS-AVAILABLE, AND MAKES NO REPRESENTATIONS OR WARRANTIES OF ANY KIND CONCERNING THE LICENSED MATERIAL, WHETHER EXPRESS, IMPLIED, STATUTORY, OR OTHER. THIS INCLUDES, WITHOUT LIMITATION, WARRANTIES OF TITLE, MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, NON-INFRINGEMENT, ABSENCE OF LATENT OR OTHER DEFECTS, ACCURACY, OR THE PRESENCE OR ABSENCE OF ERRORS, WHETHER OR NOT KNOWN OR DISCOVERABLE. WHERE DISCLAIMERS OF WARRANTIES ARE NOT ALLOWED IN FULL OR IN PART, THIS DISCLAIMER MAY NOT APPLY TO YOU. b. TO THE EXTENT POSSIBLE, IN NO EVENT WILL THE LICENSOR BE LIABLE TO YOU ON ANY LEGAL THEORY (INCLUDING, WITHOUT LIMITATION, NEGLIGENCE) OR OTHERWISE FOR ANY DIRECT, SPECIAL, INDIRECT, INCIDENTAL, CONSEQUENTIAL, PUNITIVE, EXEMPLARY, OR OTHER LOSSES, COSTS, EXPENSES, OR DAMAGES ARISING OUT OF THIS PUBLIC LICENSE OR USE OF THE LICENSED MATERIAL, EVEN IF THE LICENSOR HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH LOSSES, COSTS, EXPENSES, OR DAMAGES. WHERE A LIMITATION OF LIABILITY IS NOT ALLOWED IN FULL OR IN PART, THIS LIMITATION MAY NOT APPLY TO YOU. c. The disclaimer of warranties and limitation of liability provided above shall be interpreted in a manner that, to the extent possible, most closely approximates an absolute disclaimer and waiver of all liability. Section 6 -- Term and Termination. a. This Public License applies for the term of the Copyright and Similar Rights licensed here. However, if You fail to comply with this Public License, then Your rights under this Public License terminate automatically. b. Where Your right to use the Licensed Material has terminated under Section 6(a), it reinstates: 1. automatically as of the date the violation is cured, provided it is cured within 30 days of Your discovery of the violation; or 2. upon express reinstatement by the Licensor. For the avoidance of doubt, this Section 6(b) does not affect any right the Licensor may have to seek remedies for Your violations of this Public License. c. For the avoidance of doubt, the Licensor may also offer the Licensed Material under separate terms or conditions or stop distributing the Licensed Material at any time; however, doing so will not terminate this Public License. d. Sections 1, 5, 6, 7, and 8 survive termination of this Public License. Section 7 -- Other Terms and Conditions. a. The Licensor shall not be bound by any additional or different terms or conditions communicated by You unless expressly agreed. b. Any arrangements, understandings, or agreements regarding the Licensed Material not stated herein are separate from and independent of the terms and conditions of this Public License. Section 8 -- Interpretation. a. For the avoidance of doubt, this Public License does not, and shall not be interpreted to, reduce, limit, restrict, or impose conditions on any use of the Licensed Material that could lawfully be made without permission under this Public License. b. To the extent possible, if any provision of this Public License is deemed unenforceable, it shall be automatically reformed to the minimum extent necessary to make it enforceable. If the provision cannot be reformed, it shall be severed from this Public License without affecting the enforceability of the remaining terms and conditions. c. No term or condition of this Public License will be waived and no failure to comply consented to unless expressly agreed to by the Licensor. d. Nothing in this Public License constitutes or may be interpreted as a limitation upon, or waiver of, any privileges and immunities that apply to the Licensor or You, including from the legal processes of any jurisdiction or authority. ======================================================================= Creative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the \u201cLicensor.\u201d The text of the Creative Commons public licenses is dedicated to the public domain under the CC0 Public Domain Dedication. Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark \"Creative Commons\" or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses. Creative Commons may be contacted at creativecommons.org.","title":"License: CC BY-NC-SA"},{"location":"node-creation-2/","text":"Creating a Custom Node The AiPipeline platform is designed to be highly extensible. You can add new functionalities by creating and integrating your own custom nodes. While the platform is primarily built in .NET, a node can be implemented in any language that can communicate with RabbitMQ and gRPC. This guide uses a simple word-processor node as an example. Its single procedure, repeat-string , takes a string and a repetition count N as input, then outputs the string repeated N times. N is optional and it's default is 2. 1. Node Communication Essentials Nodes communicate with the Orchestration Runner and other nodes via RabbitMQ , a message broker. Your node needs to handle four key messaging tasks: Advertising : Periodically announce your node's capabilities to the Orchestration Runner. Listening : Receive pipeline commands from the Orchestration Runner (or other nodes). Reporting : Send the results (success or failure) of a procedure back to the runner. Forwarding : Pass the pipeline command to the next node in the sequence. RabbitMQ Setup Your node needs a connection string to the RabbitMQ broker, typically provided via a ConnectionStrings__rabbitmq environment variable. On startup, it must establish a connection. Node Advertisements Your node must periodically send an advertisement message to the node-advertisements exchange. This message informs the Orchestration Runner about your node's availability and its procedures. { \"nodeId\": \"word-processor\", \"procedures\": [ { \"id\": \"repeat-string\", \"schemaVersion\": 1, \"input\": { \"type\": \"ApObject\", \"properties\": { \"inputString\": { \"type\": \"ApString\", \"value\": \"\" }, \"repetitionCount\": { \"type\": \"ApInt\", \"value\": \"\" } }, \"nonRequiredProperties\": [\"repetitionCount\"] }, \"output\": { \"type\": \"ApObject\", \"properties\": { \"repeatedString\": { \"type\": \"ApString\", \"value\": \"\" } }, \"nonRequiredProperties\": [] } } ] } The nodeId must be a globally unique string. The procedures array lists all the functionalities your node provides, including their node-unique IDs and ApScheme input/output contracts. Dedicated Queue To receive work, your node needs its own queue. This queue must have the same name as your nodeId . You then need to bind this queue to the run-pipeline topic exchange using a topic pattern that matches your queue name: run-pipeline.<your-node-id> . This setup ensures that your node only receives messages intended for it. 2. Implementing the Procedure Logic Once the messaging setup is complete, you can focus on the core logic of your procedures. Handling Incoming Messages When a message arrives on your queue, it will contain all the information needed to execute a step in a pipeline. { \"pipelineId\": \"da44763b-cb66-4e0b-a2c9-13c94541a4e8\", \"userId\": \"9b8ee2bc-9ecb-4556-89e0-4642f0a0cab4\", \"currentStep\": { \"nodeId\": \"word-processor\", \"procedureId\": \"repeat-string\", \"orderInPipeline\": 3 }, \"currentStepInput\": { \"type\": \"ApObject\", \"properties\": { \"inputString\": { \"type\": \"ApString\", \"value\": \"This is the input of the procedure\" }, \"repetitionCount\": { \"type\": \"ApInt\", \"value\": \"3\" } }, \"nonRequiredProperties\": [\"repetitionCount\"] }, \"nextSteps\": [ { \"nodeId\": \"next-node-id-1\", \"procedureId\": \"next-node-requested-procedure-id\", \"orderInPipeline\": 4, \"outputValueSelector\": \"0.innerParamXyz\" }, { \"nodeId\": \"next-node-id-2\", \"procedureId\": \"next-node-requested-procedure-id-2\", \"orderInPipeline\": 5 } ], \"fileReferences\": [ { \"id\": \"92d95e90-5c3f-45aa-ab04-e1533e5153ee\", \"storageProvider\": \"minio\", \"path\": \"short-term-files/92d95e90-5c3f-45aa-ab04-e1533e5153ee.png\", \"contentType\": \"image/png\" } ] } Your node must: Extract the procedureId from the currentStep object. Route the message to the corresponding procedure's execution logic. Provide the currentStepInput as the procedure's input data. Success: Completing a Step If your procedure runs successfully, you must do two things: Report Success : Publish a message to the completed-pipeline-steps exchange. This message should contain the pipelineId , the procedure's identifier, a timestamp, and your procedure's ApScheme output as the result . If the original message had an outputValueSelector , you must apply it to your output before sending. { \"pipelineId\": \"da44763b-cb66-4e0b-a2c9-13c94541a4e8\", \"procedureIdentifier\": { \"nodeId\": \"word-processor\", \"procedureId\": \"repeat-string\", \"orderInPipeline\": 3 }, \"completedAt\": \"2024-01-24T06:09:19.384957Z\", \"result\": { \"type\": \"ApObject\", \"properties\": { \"repeatedString\": { \"type\": \"ApString\", \"value\": \"This is the input of the procedureThis is the input of the procedureThis is the input of the procedure\" } } }, \"nextSteps\": [ { \"nodeId\": \"next-node-id-1\", \"procedureId\": \"next-node-requested-procedure-id\", \"orderInPipeline\": 4, \"outputValueSelector\": \"0.innerParamXyz\" }, { \"nodeId\": \"next-node-id-2\", \"procedureId\": \"next-node-requested-procedure-id-2\", \"orderInPipeline\": 5 } ] } 2. Forward Pipeline : If the nextSteps array is not empty, create a new message for the next node. This message is identical to the one you received, but with the following changes: The currentStep is now the first step from the original nextSteps . The currentStepInput is now your procedure's output (or value selected by optional outputValueSelector ). The first step is removed from the nextSteps array. Any new file references are added to the fileReferences list. { \"pipelineId\": \"da44763b-cb66-4e0b-a2c9-13c94541a4e8\", \"userId\": \"9b8ee2bc-9ecb-4556-89e0-4642f0a0cab4\", \"currentStep\": { \"nodeId\": \"next-node-id-1\", \"procedureId\": \"next-node-requested-procedure-id\", \"orderInPipeline\": 4, \"outputValueSelector\": \"0.innerParamXyz\" }, \"currentStepInput\": { \"type\": \"ApObject\", \"properties\": { \"repeatedString\": { \"type\": \"ApString\", \"value\": \"This is the input of the procedureThis is the input of the procedureThis is the input of the procedure\" } } }, \"nextSteps\": [ { \"nodeId\": \"next-node-id-2\", \"procedureId\": \"next-node-requested-procedure-id-2\", \"orderInPipeline\": 5 } ], \"fileReferences\": [ { \"id\": \"92d95e90-5c3f-45aa-ab04-e1533e5153ee\", \"storageProvider\": \"minio\", \"path\": \"short-term-files/92d95e90-5c3f-45aa-ab04-e1533e5153ee.png\", \"contentType\": \"image/png\" } ] } Publish this new message to the run-pipeline exchange with the topic run-pipeline.<next-node-id> . Failure: Handling Errors If your procedure fails, it must stop the pipeline and report the error. Publish a single message to the failed-pipelines exchange. This message should include: pipelineId and procedureIdentifier to identify the failure. failedAt timestamp. A failureCode (a numeric code semantically consistent with HTTP status codes, e.g., 422 for bad input). A descriptive failureReason . An optional exceptionMessage for technical details. The remainingNotCompletedSteps to show which parts of the pipeline were skipped. { \"pipelineId\": \"da44763b-cb66-4e0b-a2c9-13c94541a4e8\", \"procedureIdentifier\": { \"nodeId\": \"word-processor\", \"procedureId\": \"repeat-string\", \"orderInPipeline\": 3 }, \"failedAt\": \"2024-01-24T06:09:19.384957Z\", \"failureCode\": 422, \"failureReason\": \"The provided repetition count wasn't a positive number ('-20'), which is not allowed.\", \"exceptionMessage\": \"This is an optional string where you can provide exception details if your pipeline failed unexpectedly\", \"remainingNotCompletedSteps\": [ { \"nodeId\": \"next-node-id-1\", \"procedureId\": \"next-node-requested-procedure-id\", \"orderInPipeline\": 4, \"outputValueSelector\": \"0.innerParamXyz\" }, { \"nodeId\": \"next-node-id-2\", \"procedureId\": \"next-node-requested-procedure-id-2\", \"orderInPipeline\": 5 } ] } Handling Files The platform includes a dedicated gRPC file service for managing file data. Download : If an ApFile is in your input, find its ID in the fileReferences list. Use the gRPC service to download the file data for processing. Upload : If your procedure generates a new file, upload it to the gRPC service. You must provide the file's data, its contentType , a new GUID, the userId from the incoming message, and a storageScope . The storage scope determines how long the file will be kept and can be one of three values: long-term-files , short-term-files , or temp-files . The service will return a reference that must be added to the fileReferences list if the pipeline continues. Example Node in .NET The shared .NET codebase handles most of the complex messaging and routing logic for you. Here\u2019s a streamlined guide for implementing the word-processor example. Project Setup Create a new Web API project in the solution: AiPipeline.<optional-node-group-name>.WordProcessor . Add references to the following shared projects: AiPipeline.Orchestration.Shared.All , AiPipeline.Orchestration.Shared.Nodes , AiPipeline.ServiceDefaults (only for local deployment), and AiPipeline.Shared . Declare Messaging Constants In the MessagingConstants.cs file (in AiPipeline.Orchestration.Shared.All ), add your node's unique ID. public static class MessagingConstants { // ... other constants public static string WordProcessorId => \"word-processor\"; } Next, in WolverineExtensions.cs , bind your node's queue to the run-pipeline exchange. public static RabbitMqTransportExpression DeclareExchanges(this RabbitMqTransportExpression expression) { return expression .DeclareExchange(MessagingConstants.RunPipelineExchangeName, exc => { // ... other bindings exc.BindTopic($\"{MessagingConstants.RunPipelineExchangeName}.{MessagingConstants.WordProcessorId}\") .ToQueue(MessagingConstants.WordProcessorId); }); } Program.cs Configuration Configure Program.cs to set up Wolverine, register your procedures, and enable file services. The shared utilities handle all the background work. var builder = WebApplication.CreateBuilder(args); // Configures connection to RabbitMq message broker via WolverineFx builder.Host.UseWolverine(opt => { opt.UseRabbitMqUsingNamedConnection(\"rabbitmq\") // This connects your node to the RabbitMq broker. The connectionString should added to configuration as 'ConnectionStrings__rabbitmq' .DeclareExchanges() // Ensures all exchanges and queues are properly declared .AutoProvision(); // Ensures RabbitMq configuration is persisted on the broker opt.ConfigureMessagePublishing(); // Adds rules on how the messages should be published in the RabbitMq broker opt.ApplyCustomConfiguration(); // Adds custom configuration on message parsing (ApElements) opt.ListenToRabbitQueue(MessagingConstants.WordProcessorId); // Ensures your node receives messages for procedure execution // Adds a separate hosted service which will publish your node and procedure advertisements to the OrchestrationRunner opt.Services.AddHostedService(provider => new NodeAdvertisementProducerService( serviceProvider: provider, nodeId: MessagingConstants.WordProcessorId, assemblies: typeof(DependencyInjection).Assembly ) ); }); // Injects 'IFileReferenceDownloaderService' and 'IFileReferenceUploaderService' to work with files via gRPC File Service builder.Services.AddFileManipulation(builder.Configuration); // Injects procedure routing and registers all procedures (implementations of IProcedure) from your assemblies builder.Services.AddProcedureRoutingFromAssemblies(typeof(Program).Assembly); var app = builder.Build(); app.Run(); Implement Your Procedure Create a RepeatStringProcedure class that implements the IProcedure interface. You only need to define its ID, schemas, and the ExecuteAsync method. public class RepeatStringProcedure : IProcedure { public string Id => \"repeat-string\"; public int SchemaVersion => 1; public IApElement InputSchema => new ApObject( properties: new Dictionary<string, IApElement>() { { \"inputString\", ApString.Template() }, { \"repetitionCount\", ApInt.Template() }, }, nonRequiredProperties: [\"repetitionCount\"] ); public IApElement OutputSchema => new ApObject( properties: new Dictionary<string, IApElement>() { { \"repeatedString\", ApString.Template() } } ); public async Task<DataResult<IApElement>> ExecuteAsync(RunPipelineStep step) { var inputValuesResult = ExtractInputValues(step.CurrentStepInput); if (inputValuesResult.IsFailure) return DataResult<IApElement>.Failure(inputValuesResult.Failures); var inputValues = inputValuesResult.Data!; var result = string.Concat(Enumerable.Repeat(inputValues.Item1, inputValues.Item2)); return DataResult<IApElement>.Success( new ApObject( properties: new() { { \"repeatedString\", new ApString(result) } } ) ); } private DataResult<(string, int)> ExtractInputValues(IApElement stepInput) { if (stepInput is ApObject input) { var hasInputString = input.TryGetValueCaseInsensitive(\"inputString\", out var inputString); if (!hasInputString || inputString is not ApString) return DataResult<(string, int)>.Invalid( $\"Property 'inputString' is required and must be of type {nameof(ApString)}\"); input.TryGetValueCaseInsensitive(\"repetitionCount\", out var repCnt); var repetitionCount = repCnt is ApInt repCntInt ? repCntInt.Value : 2; if (repetitionCount < 1) return DataResult<(string, int)>.Invalid( $\"The provided repetition count wasn't a positive number ('{repetitionCount}'), which is not allowed.\"); return DataResult<(string, int)>.Success(( ((ApString)inputString).Value, repetitionCount )); } return DataResult<(string, int)>.Invalid(\"Input has an invalid scheme.\"); } } The ProcedureRouter takes care of all the message-passing and error-handling boilerplate. Your ExecuteAsync method only needs to focus on the business logic and returning a DataResult . Running Your Node To run your node in a local Aspire debug environment, add a project reference to it in the AiPipeline.Apphost project. // ... other projects var wordProcessorNode = builder.AddProject<AiPipeline_WordProcessor>(\"WordProcessorNode\") .WithReference(rabbitMq) // rabbitMq already prepared in Program.cs .WaitFor(rabbitMq) .WithReference(fileService) // fileService already prepared in Program.cs; For production, containerize your project with a Dockerfile and add it to your deployment configuration (e.g., Kubernetes, Docker Compose), ensuring you provide all necessary secrets and connection strings. A Note on DataResult and Result The DataResult<T> and Result classes are not a mandatory part of building an AiPipeline node, but they are an integral utility within the shared codebase. They are a C# implementation of a union type, designed to explicitly handle success and failure states in a clean, composable way. Instead of throwing exceptions or returning null to indicate a failure, these classes allow you to return a single object that clearly contains either the expected data on success or a collection of Failure objects on failure. This pattern is essential when implementing the IProcedure interface, as the ExecuteAsync method requires a return type of Task<DataResult<IApElement>> . The ProcedureRouter relies on this explicit result to automatically handle the next steps in the pipeline: If IsSuccess is true , the ProcedureRouter takes the Data property and passes it to the next node. If IsSuccess is false , the router uses the Failures property to construct the failure message and publish it to the failed-pipelines queue. The static factory methods on the Result and DataResult<T> classes provide a simple way to create these objects for common scenarios. They align with standard HTTP status codes, such as Invalid(422) for bad input or NotFound(404) for missing resources, making the failure reasons clear and consistent across the platform.","title":"Create your own node"},{"location":"node-creation-2/#creating-a-custom-node","text":"The AiPipeline platform is designed to be highly extensible. You can add new functionalities by creating and integrating your own custom nodes. While the platform is primarily built in .NET, a node can be implemented in any language that can communicate with RabbitMQ and gRPC. This guide uses a simple word-processor node as an example. Its single procedure, repeat-string , takes a string and a repetition count N as input, then outputs the string repeated N times. N is optional and it's default is 2.","title":"Creating a Custom Node"},{"location":"node-creation-2/#1-node-communication-essentials","text":"Nodes communicate with the Orchestration Runner and other nodes via RabbitMQ , a message broker. Your node needs to handle four key messaging tasks: Advertising : Periodically announce your node's capabilities to the Orchestration Runner. Listening : Receive pipeline commands from the Orchestration Runner (or other nodes). Reporting : Send the results (success or failure) of a procedure back to the runner. Forwarding : Pass the pipeline command to the next node in the sequence.","title":"1. Node Communication Essentials"},{"location":"node-creation-2/#rabbitmq-setup","text":"Your node needs a connection string to the RabbitMQ broker, typically provided via a ConnectionStrings__rabbitmq environment variable. On startup, it must establish a connection.","title":"RabbitMQ Setup"},{"location":"node-creation-2/#node-advertisements","text":"Your node must periodically send an advertisement message to the node-advertisements exchange. This message informs the Orchestration Runner about your node's availability and its procedures. { \"nodeId\": \"word-processor\", \"procedures\": [ { \"id\": \"repeat-string\", \"schemaVersion\": 1, \"input\": { \"type\": \"ApObject\", \"properties\": { \"inputString\": { \"type\": \"ApString\", \"value\": \"\" }, \"repetitionCount\": { \"type\": \"ApInt\", \"value\": \"\" } }, \"nonRequiredProperties\": [\"repetitionCount\"] }, \"output\": { \"type\": \"ApObject\", \"properties\": { \"repeatedString\": { \"type\": \"ApString\", \"value\": \"\" } }, \"nonRequiredProperties\": [] } } ] } The nodeId must be a globally unique string. The procedures array lists all the functionalities your node provides, including their node-unique IDs and ApScheme input/output contracts.","title":"Node Advertisements"},{"location":"node-creation-2/#dedicated-queue","text":"To receive work, your node needs its own queue. This queue must have the same name as your nodeId . You then need to bind this queue to the run-pipeline topic exchange using a topic pattern that matches your queue name: run-pipeline.<your-node-id> . This setup ensures that your node only receives messages intended for it.","title":"Dedicated Queue"},{"location":"node-creation-2/#2-implementing-the-procedure-logic","text":"Once the messaging setup is complete, you can focus on the core logic of your procedures.","title":"2. Implementing the Procedure Logic"},{"location":"node-creation-2/#handling-incoming-messages","text":"When a message arrives on your queue, it will contain all the information needed to execute a step in a pipeline. { \"pipelineId\": \"da44763b-cb66-4e0b-a2c9-13c94541a4e8\", \"userId\": \"9b8ee2bc-9ecb-4556-89e0-4642f0a0cab4\", \"currentStep\": { \"nodeId\": \"word-processor\", \"procedureId\": \"repeat-string\", \"orderInPipeline\": 3 }, \"currentStepInput\": { \"type\": \"ApObject\", \"properties\": { \"inputString\": { \"type\": \"ApString\", \"value\": \"This is the input of the procedure\" }, \"repetitionCount\": { \"type\": \"ApInt\", \"value\": \"3\" } }, \"nonRequiredProperties\": [\"repetitionCount\"] }, \"nextSteps\": [ { \"nodeId\": \"next-node-id-1\", \"procedureId\": \"next-node-requested-procedure-id\", \"orderInPipeline\": 4, \"outputValueSelector\": \"0.innerParamXyz\" }, { \"nodeId\": \"next-node-id-2\", \"procedureId\": \"next-node-requested-procedure-id-2\", \"orderInPipeline\": 5 } ], \"fileReferences\": [ { \"id\": \"92d95e90-5c3f-45aa-ab04-e1533e5153ee\", \"storageProvider\": \"minio\", \"path\": \"short-term-files/92d95e90-5c3f-45aa-ab04-e1533e5153ee.png\", \"contentType\": \"image/png\" } ] } Your node must: Extract the procedureId from the currentStep object. Route the message to the corresponding procedure's execution logic. Provide the currentStepInput as the procedure's input data.","title":"Handling Incoming Messages"},{"location":"node-creation-2/#success-completing-a-step","text":"If your procedure runs successfully, you must do two things: Report Success : Publish a message to the completed-pipeline-steps exchange. This message should contain the pipelineId , the procedure's identifier, a timestamp, and your procedure's ApScheme output as the result . If the original message had an outputValueSelector , you must apply it to your output before sending. { \"pipelineId\": \"da44763b-cb66-4e0b-a2c9-13c94541a4e8\", \"procedureIdentifier\": { \"nodeId\": \"word-processor\", \"procedureId\": \"repeat-string\", \"orderInPipeline\": 3 }, \"completedAt\": \"2024-01-24T06:09:19.384957Z\", \"result\": { \"type\": \"ApObject\", \"properties\": { \"repeatedString\": { \"type\": \"ApString\", \"value\": \"This is the input of the procedureThis is the input of the procedureThis is the input of the procedure\" } } }, \"nextSteps\": [ { \"nodeId\": \"next-node-id-1\", \"procedureId\": \"next-node-requested-procedure-id\", \"orderInPipeline\": 4, \"outputValueSelector\": \"0.innerParamXyz\" }, { \"nodeId\": \"next-node-id-2\", \"procedureId\": \"next-node-requested-procedure-id-2\", \"orderInPipeline\": 5 } ] } 2. Forward Pipeline : If the nextSteps array is not empty, create a new message for the next node. This message is identical to the one you received, but with the following changes: The currentStep is now the first step from the original nextSteps . The currentStepInput is now your procedure's output (or value selected by optional outputValueSelector ). The first step is removed from the nextSteps array. Any new file references are added to the fileReferences list. { \"pipelineId\": \"da44763b-cb66-4e0b-a2c9-13c94541a4e8\", \"userId\": \"9b8ee2bc-9ecb-4556-89e0-4642f0a0cab4\", \"currentStep\": { \"nodeId\": \"next-node-id-1\", \"procedureId\": \"next-node-requested-procedure-id\", \"orderInPipeline\": 4, \"outputValueSelector\": \"0.innerParamXyz\" }, \"currentStepInput\": { \"type\": \"ApObject\", \"properties\": { \"repeatedString\": { \"type\": \"ApString\", \"value\": \"This is the input of the procedureThis is the input of the procedureThis is the input of the procedure\" } } }, \"nextSteps\": [ { \"nodeId\": \"next-node-id-2\", \"procedureId\": \"next-node-requested-procedure-id-2\", \"orderInPipeline\": 5 } ], \"fileReferences\": [ { \"id\": \"92d95e90-5c3f-45aa-ab04-e1533e5153ee\", \"storageProvider\": \"minio\", \"path\": \"short-term-files/92d95e90-5c3f-45aa-ab04-e1533e5153ee.png\", \"contentType\": \"image/png\" } ] } Publish this new message to the run-pipeline exchange with the topic run-pipeline.<next-node-id> .","title":"Success: Completing a Step"},{"location":"node-creation-2/#failure-handling-errors","text":"If your procedure fails, it must stop the pipeline and report the error. Publish a single message to the failed-pipelines exchange. This message should include: pipelineId and procedureIdentifier to identify the failure. failedAt timestamp. A failureCode (a numeric code semantically consistent with HTTP status codes, e.g., 422 for bad input). A descriptive failureReason . An optional exceptionMessage for technical details. The remainingNotCompletedSteps to show which parts of the pipeline were skipped. { \"pipelineId\": \"da44763b-cb66-4e0b-a2c9-13c94541a4e8\", \"procedureIdentifier\": { \"nodeId\": \"word-processor\", \"procedureId\": \"repeat-string\", \"orderInPipeline\": 3 }, \"failedAt\": \"2024-01-24T06:09:19.384957Z\", \"failureCode\": 422, \"failureReason\": \"The provided repetition count wasn't a positive number ('-20'), which is not allowed.\", \"exceptionMessage\": \"This is an optional string where you can provide exception details if your pipeline failed unexpectedly\", \"remainingNotCompletedSteps\": [ { \"nodeId\": \"next-node-id-1\", \"procedureId\": \"next-node-requested-procedure-id\", \"orderInPipeline\": 4, \"outputValueSelector\": \"0.innerParamXyz\" }, { \"nodeId\": \"next-node-id-2\", \"procedureId\": \"next-node-requested-procedure-id-2\", \"orderInPipeline\": 5 } ] }","title":"Failure: Handling Errors"},{"location":"node-creation-2/#handling-files","text":"The platform includes a dedicated gRPC file service for managing file data. Download : If an ApFile is in your input, find its ID in the fileReferences list. Use the gRPC service to download the file data for processing. Upload : If your procedure generates a new file, upload it to the gRPC service. You must provide the file's data, its contentType , a new GUID, the userId from the incoming message, and a storageScope . The storage scope determines how long the file will be kept and can be one of three values: long-term-files , short-term-files , or temp-files . The service will return a reference that must be added to the fileReferences list if the pipeline continues.","title":"Handling Files"},{"location":"node-creation-2/#example-node-in-net","text":"The shared .NET codebase handles most of the complex messaging and routing logic for you. Here\u2019s a streamlined guide for implementing the word-processor example.","title":"Example Node in .NET"},{"location":"node-creation-2/#project-setup","text":"Create a new Web API project in the solution: AiPipeline.<optional-node-group-name>.WordProcessor . Add references to the following shared projects: AiPipeline.Orchestration.Shared.All , AiPipeline.Orchestration.Shared.Nodes , AiPipeline.ServiceDefaults (only for local deployment), and AiPipeline.Shared .","title":"Project Setup"},{"location":"node-creation-2/#declare-messaging-constants","text":"In the MessagingConstants.cs file (in AiPipeline.Orchestration.Shared.All ), add your node's unique ID. public static class MessagingConstants { // ... other constants public static string WordProcessorId => \"word-processor\"; } Next, in WolverineExtensions.cs , bind your node's queue to the run-pipeline exchange. public static RabbitMqTransportExpression DeclareExchanges(this RabbitMqTransportExpression expression) { return expression .DeclareExchange(MessagingConstants.RunPipelineExchangeName, exc => { // ... other bindings exc.BindTopic($\"{MessagingConstants.RunPipelineExchangeName}.{MessagingConstants.WordProcessorId}\") .ToQueue(MessagingConstants.WordProcessorId); }); }","title":"Declare Messaging Constants"},{"location":"node-creation-2/#programcs-configuration","text":"Configure Program.cs to set up Wolverine, register your procedures, and enable file services. The shared utilities handle all the background work. var builder = WebApplication.CreateBuilder(args); // Configures connection to RabbitMq message broker via WolverineFx builder.Host.UseWolverine(opt => { opt.UseRabbitMqUsingNamedConnection(\"rabbitmq\") // This connects your node to the RabbitMq broker. The connectionString should added to configuration as 'ConnectionStrings__rabbitmq' .DeclareExchanges() // Ensures all exchanges and queues are properly declared .AutoProvision(); // Ensures RabbitMq configuration is persisted on the broker opt.ConfigureMessagePublishing(); // Adds rules on how the messages should be published in the RabbitMq broker opt.ApplyCustomConfiguration(); // Adds custom configuration on message parsing (ApElements) opt.ListenToRabbitQueue(MessagingConstants.WordProcessorId); // Ensures your node receives messages for procedure execution // Adds a separate hosted service which will publish your node and procedure advertisements to the OrchestrationRunner opt.Services.AddHostedService(provider => new NodeAdvertisementProducerService( serviceProvider: provider, nodeId: MessagingConstants.WordProcessorId, assemblies: typeof(DependencyInjection).Assembly ) ); }); // Injects 'IFileReferenceDownloaderService' and 'IFileReferenceUploaderService' to work with files via gRPC File Service builder.Services.AddFileManipulation(builder.Configuration); // Injects procedure routing and registers all procedures (implementations of IProcedure) from your assemblies builder.Services.AddProcedureRoutingFromAssemblies(typeof(Program).Assembly); var app = builder.Build(); app.Run();","title":"Program.cs Configuration"},{"location":"node-creation-2/#implement-your-procedure","text":"Create a RepeatStringProcedure class that implements the IProcedure interface. You only need to define its ID, schemas, and the ExecuteAsync method. public class RepeatStringProcedure : IProcedure { public string Id => \"repeat-string\"; public int SchemaVersion => 1; public IApElement InputSchema => new ApObject( properties: new Dictionary<string, IApElement>() { { \"inputString\", ApString.Template() }, { \"repetitionCount\", ApInt.Template() }, }, nonRequiredProperties: [\"repetitionCount\"] ); public IApElement OutputSchema => new ApObject( properties: new Dictionary<string, IApElement>() { { \"repeatedString\", ApString.Template() } } ); public async Task<DataResult<IApElement>> ExecuteAsync(RunPipelineStep step) { var inputValuesResult = ExtractInputValues(step.CurrentStepInput); if (inputValuesResult.IsFailure) return DataResult<IApElement>.Failure(inputValuesResult.Failures); var inputValues = inputValuesResult.Data!; var result = string.Concat(Enumerable.Repeat(inputValues.Item1, inputValues.Item2)); return DataResult<IApElement>.Success( new ApObject( properties: new() { { \"repeatedString\", new ApString(result) } } ) ); } private DataResult<(string, int)> ExtractInputValues(IApElement stepInput) { if (stepInput is ApObject input) { var hasInputString = input.TryGetValueCaseInsensitive(\"inputString\", out var inputString); if (!hasInputString || inputString is not ApString) return DataResult<(string, int)>.Invalid( $\"Property 'inputString' is required and must be of type {nameof(ApString)}\"); input.TryGetValueCaseInsensitive(\"repetitionCount\", out var repCnt); var repetitionCount = repCnt is ApInt repCntInt ? repCntInt.Value : 2; if (repetitionCount < 1) return DataResult<(string, int)>.Invalid( $\"The provided repetition count wasn't a positive number ('{repetitionCount}'), which is not allowed.\"); return DataResult<(string, int)>.Success(( ((ApString)inputString).Value, repetitionCount )); } return DataResult<(string, int)>.Invalid(\"Input has an invalid scheme.\"); } } The ProcedureRouter takes care of all the message-passing and error-handling boilerplate. Your ExecuteAsync method only needs to focus on the business logic and returning a DataResult .","title":"Implement Your Procedure"},{"location":"node-creation-2/#running-your-node","text":"To run your node in a local Aspire debug environment, add a project reference to it in the AiPipeline.Apphost project. // ... other projects var wordProcessorNode = builder.AddProject<AiPipeline_WordProcessor>(\"WordProcessorNode\") .WithReference(rabbitMq) // rabbitMq already prepared in Program.cs .WaitFor(rabbitMq) .WithReference(fileService) // fileService already prepared in Program.cs; For production, containerize your project with a Dockerfile and add it to your deployment configuration (e.g., Kubernetes, Docker Compose), ensuring you provide all necessary secrets and connection strings.","title":"Running Your Node"},{"location":"node-creation-2/#a-note-on-dataresult-and-result","text":"The DataResult<T> and Result classes are not a mandatory part of building an AiPipeline node, but they are an integral utility within the shared codebase. They are a C# implementation of a union type, designed to explicitly handle success and failure states in a clean, composable way. Instead of throwing exceptions or returning null to indicate a failure, these classes allow you to return a single object that clearly contains either the expected data on success or a collection of Failure objects on failure. This pattern is essential when implementing the IProcedure interface, as the ExecuteAsync method requires a return type of Task<DataResult<IApElement>> . The ProcedureRouter relies on this explicit result to automatically handle the next steps in the pipeline: If IsSuccess is true , the ProcedureRouter takes the Data property and passes it to the next node. If IsSuccess is false , the router uses the Failures property to construct the failure message and publish it to the failed-pipelines queue. The static factory methods on the Result and DataResult<T> classes provide a simple way to create these objects for common scenarios. They align with standard HTTP status codes, such as Invalid(422) for bad input or NotFound(404) for missing resources, making the failure reasons clear and consistent across the platform.","title":"A Note on DataResult and Result"},{"location":"orchestration-runner/","text":"Orchestration Runner The Orchestration Runner serves as the central control for the AiPipeline platform. It manages several core functionalities and provides a public RESTful API with dedicated endpoint groups for user interaction. 1. Authentication and Authorization (Auth) Access to the AiPipeline platform is restricted to authenticated users and services. The Authentication API provides a secure way to manage access. POST /Register : Creates a new user account with provided credentials. POST /Login : Authenticates a user and returns a pair of access and refresh tokens. POST /Refresh : Exchanges an existing token pair for a new one, extending the authenticated session. POST /ApiKey : Generates a new, uniquely named API key for current user. This key can be used by other services to access the platform. The API key is only returned once and cannot be retrieved later. DELETE /ApiKey/{name} : Deletes the specified API key. Authentication Methods For Users : Use the access token from the /Login endpoint. Include it in the Authorization HTTP header with the Bearer scheme => Authorization: Bearer <your_access_token> . For Services : Use the API key from the /ApiKey endpoint. Include it directly in the Authorization HTTP header => Authorization: <your_api_key> . Authorization Rules Authenticated users have full access to all endpoints. However, authorization is scoped to the user, meaning they can only view and manage content they have created, including files, pipeline results, and personal data. This restriction does not apply to the Node Discovery endpoints, which are public for all authenticated users. It should also be noted that authenticated services (via ApiKeys) create all content under their owner user's id and also have restricted access to some endpoints. Namely, a service authenticated via ApiKey may not update or delete user accounts or create/delete ApiKeys. 2. File Management (Files) The Orchestration Runner provides an API for users to interact with the central File Service. Internally, the runner communicates with the File Service using its gRPC SDK. GET /Files : Lists all files owned by the user. GET /Files/{id} : Retrieves the structured metadata for a specific file. GET /Files/{id}/Download : Downloads the raw data of a file. POST /Files/Upload : Uploads a new file, creating a new file record and storing the data in the File Service. DELETE /Files/{id} : Deletes a file record and its associated data. 3. Node Discovery (Nodes) This functionality provides a simple way to discover and inspect all available nodes on the platform. The Orchestration Runner keeps up-to-date records of all available nodes in it's database. It gathers this data by listening on a RabbitMQ queue, which is used by the nodes to advertise themselves, their procedures and their i/o schemes. GET /Nodes : Lists all available nodes the Orchestration Runner sees. These records contain the nodes' procedures and the procedures' i/o schemes 4. Running pipelines (Pipelines) This is the core functionality of the Orchestration Runner. Endpoints in this group allow the user to construct an arbitrary pipeline from gathered information about available nodes. Generally user outlines the flow of the pipeline using node-procedure identifier list and provides the initial input (compatible with the first procedure in the sequence). More info on how to run pipelines available on Running Pipelines . POST /Pipelines : Runs a pipeline on the background, not awaiting the result. POST /Pipelines/Awaited : Runs a pipeline in the same manner as in the standard /Pipelines endpoint, but the Runner only responds after the pipeline has completed (or user-provided timeout runs out). Returns a pipeline result directly back to the user POST /Pipelines/Batch : Runs the same pipeline on multiple inputs in parallel. Number of pipelines is derrived from the number of provided inputs. Completion of pipelines is not awaited. 5. Pipeline Result Analysis (PipelineResults) This functionality is focused simply on listing and display of results of pipelines, where user can find step-by-step process of the finished pipeline, seeing each partial result or reason of failure in case pipeline doesn't finish successfully. GET /PipelineResults : Lists results of all current user pipelines GET /PipelineResults/{id} : Gets a result of current user pipeline with the specified pipeline id. GET /PipelineResults/Batch/{id} : Gets a sequence of pipeline results for pipelines ran from a single batch (using the Pipelines/Batch endpoint). 6. User Management (Users) Users can manage their accounts through this set of endpoints. GET /Users/{id} : Retrieves public details of a user. PUT /Users/{id} : Updates the authenticated user's account details. DELETE /Users/{id} : Deletes the authenticated user's account and all associated data","title":"Orchestration runner"},{"location":"orchestration-runner/#orchestration-runner","text":"The Orchestration Runner serves as the central control for the AiPipeline platform. It manages several core functionalities and provides a public RESTful API with dedicated endpoint groups for user interaction.","title":"Orchestration Runner"},{"location":"orchestration-runner/#1-authentication-and-authorization-auth","text":"Access to the AiPipeline platform is restricted to authenticated users and services. The Authentication API provides a secure way to manage access. POST /Register : Creates a new user account with provided credentials. POST /Login : Authenticates a user and returns a pair of access and refresh tokens. POST /Refresh : Exchanges an existing token pair for a new one, extending the authenticated session. POST /ApiKey : Generates a new, uniquely named API key for current user. This key can be used by other services to access the platform. The API key is only returned once and cannot be retrieved later. DELETE /ApiKey/{name} : Deletes the specified API key.","title":"1. Authentication and Authorization (Auth)"},{"location":"orchestration-runner/#authentication-methods","text":"For Users : Use the access token from the /Login endpoint. Include it in the Authorization HTTP header with the Bearer scheme => Authorization: Bearer <your_access_token> . For Services : Use the API key from the /ApiKey endpoint. Include it directly in the Authorization HTTP header => Authorization: <your_api_key> .","title":"Authentication Methods"},{"location":"orchestration-runner/#authorization-rules","text":"Authenticated users have full access to all endpoints. However, authorization is scoped to the user, meaning they can only view and manage content they have created, including files, pipeline results, and personal data. This restriction does not apply to the Node Discovery endpoints, which are public for all authenticated users. It should also be noted that authenticated services (via ApiKeys) create all content under their owner user's id and also have restricted access to some endpoints. Namely, a service authenticated via ApiKey may not update or delete user accounts or create/delete ApiKeys.","title":"Authorization Rules"},{"location":"orchestration-runner/#2-file-management-files","text":"The Orchestration Runner provides an API for users to interact with the central File Service. Internally, the runner communicates with the File Service using its gRPC SDK. GET /Files : Lists all files owned by the user. GET /Files/{id} : Retrieves the structured metadata for a specific file. GET /Files/{id}/Download : Downloads the raw data of a file. POST /Files/Upload : Uploads a new file, creating a new file record and storing the data in the File Service. DELETE /Files/{id} : Deletes a file record and its associated data.","title":"2. File Management (Files)"},{"location":"orchestration-runner/#3-node-discovery-nodes","text":"This functionality provides a simple way to discover and inspect all available nodes on the platform. The Orchestration Runner keeps up-to-date records of all available nodes in it's database. It gathers this data by listening on a RabbitMQ queue, which is used by the nodes to advertise themselves, their procedures and their i/o schemes. GET /Nodes : Lists all available nodes the Orchestration Runner sees. These records contain the nodes' procedures and the procedures' i/o schemes","title":"3. Node Discovery (Nodes)"},{"location":"orchestration-runner/#4-running-pipelines-pipelines","text":"This is the core functionality of the Orchestration Runner. Endpoints in this group allow the user to construct an arbitrary pipeline from gathered information about available nodes. Generally user outlines the flow of the pipeline using node-procedure identifier list and provides the initial input (compatible with the first procedure in the sequence). More info on how to run pipelines available on Running Pipelines . POST /Pipelines : Runs a pipeline on the background, not awaiting the result. POST /Pipelines/Awaited : Runs a pipeline in the same manner as in the standard /Pipelines endpoint, but the Runner only responds after the pipeline has completed (or user-provided timeout runs out). Returns a pipeline result directly back to the user POST /Pipelines/Batch : Runs the same pipeline on multiple inputs in parallel. Number of pipelines is derrived from the number of provided inputs. Completion of pipelines is not awaited.","title":"4. Running pipelines (Pipelines)"},{"location":"orchestration-runner/#5-pipeline-result-analysis-pipelineresults","text":"This functionality is focused simply on listing and display of results of pipelines, where user can find step-by-step process of the finished pipeline, seeing each partial result or reason of failure in case pipeline doesn't finish successfully. GET /PipelineResults : Lists results of all current user pipelines GET /PipelineResults/{id} : Gets a result of current user pipeline with the specified pipeline id. GET /PipelineResults/Batch/{id} : Gets a sequence of pipeline results for pipelines ran from a single batch (using the Pipelines/Batch endpoint).","title":"5. Pipeline Result Analysis (PipelineResults)"},{"location":"orchestration-runner/#6-user-management-users","text":"Users can manage their accounts through this set of endpoints. GET /Users/{id} : Retrieves public details of a user. PUT /Users/{id} : Updates the authenticated user's account details. DELETE /Users/{id} : Deletes the authenticated user's account and all associated data","title":"6. User Management (Users)"},{"location":"running-pipelines/","text":"Running Pipelines A pipeline is a sequence of procedures from different nodes, where the output of one procedure serves as the input for the next. For a pipeline to run successfully, the ApSchemes of each chained procedure must be compatible. This means a procedure's output type must match the next procedure's expected input type. 1. Identifying Available Nodes and Procedures Before building a pipeline, you need to know which nodes and procedures are available. You can get this information by calling the Orchestration Runner's /Nodes endpoint. The response is a JSON array of all available nodes and their procedures, including detailed ApScheme definitions for their inputs and outputs. Example Response from /Nodes { \"items\": [ { \"id\": \"tire-ocr-ocr\", \"procedures\": [ { \"id\": \"PerformSingleOcr\", \"schemaVersion\": 1, \"input\": { \"type\": \"ApObject\", \"properties\": { \"detectorType\": { \"type\": \"ApEnum\", \"value\": \"\", \"supportedCases\": [ \"GoogleGemini\", \"MistralPixtral\", \"OpenAiGpt\", \"GoogleCloudVision\", \"AzureAiVision\" ] }, \"image\": { \"type\": \"ApFile\", \"id\": \"00000000-0000-0000-0000-000000000000\", \"contentType\": \"\", \"supportedContentTypes\": [ \"image/jpeg\", \"image/png\", \"image/webp\" ] } }, \"nonRequiredProperties\": [] }, \"output\": { \"type\": \"ApObject\", \"properties\": { \"detectedCode\": { \"type\": \"ApString\", \"value\": \"\" }, \"estimatedCosts\": { \"type\": \"ApObject\", \"properties\": { \"inputUnitCount\": { \"type\": \"ApDecimal\", \"value\": 0 }, \"outputUnitCount\": { \"type\": \"ApDecimal\", \"value\": 0 }, \"billingUnit\": { \"type\": \"ApString\", \"value\": \"\" }, \"estimatedCost\": { \"type\": \"ApDecimal\", \"value\": 0 }, \"estimatedCostCurrency\": { \"type\": \"ApString\", \"value\": \"\" } }, \"nonRequiredProperties\": [] } }, \"nonRequiredProperties\": [\"estimatedCosts\"] } } ] }, { \"id\": \"tire-ocr-postprocessing\", \"procedures\": [ { \"id\": \"PerformTireCodePostprocessing\", \"schemaVersion\": 1, \"input\": { \"type\": \"ApString\", \"value\": \"\" }, \"output\": { \"type\": \"ApObject\", \"properties\": { \"rawCode\": { \"type\": \"ApString\", \"value\": \"\" }, \"postprocessedTireCode\": { \"type\": \"ApString\", \"value\": \"\" }, \"vehicleClass\": { \"type\": \"ApString\", \"value\": \"\" }, \"width\": { \"type\": \"ApDecimal\", \"value\": 0 }, \"aspectRatio\": { \"type\": \"ApDecimal\", \"value\": 0 }, \"construction\": { \"type\": \"ApString\", \"value\": \"\" }, \"diameter\": { \"type\": \"ApDecimal\", \"value\": 0 }, \"loadIndex\": { \"type\": \"ApString\", \"value\": \"\" }, \"speedRating\": { \"type\": \"ApString\", \"value\": \"\" } }, \"nonRequiredProperties\": [ \"vehicleClass\", \"width\", \"AspectRatio\", \"construction\", \"diameter\", \"loadIndex\", \"speedRating\" ] } } ] } ] } In this example, the tire-ocr-ocr node's PerformSingleOcr procedure outputs an ApObject that contains a detectedCode string. The tire-ocr-postprocessing node's PerformTireCodePostprocessing procedure expects a simple ApString as input. To chain these two, we must extract the detectedCode string from the first procedure's output object. 2. Output Value Selectors When a procedure's output scheme is more complex than the next procedure's input scheme, you can use an outputValueSelector to narrow down the output to a specific value. This ensures scheme compatibility and allows the pipeline to run. This selector is an optional parameter of each pipeline step when constructing a pipeline (more on that later). An outputValueSelector is a simple string that uses dot ( . ) separated identifiers to navigate the ApScheme JSON structure To select a property of ApObject : Use the property's name. For example, to select detectedCode from an ApObject, the selector is \"detectedCode\" . To select an item of ApList : Use the item's index. For example, if \"detectedCode\" was an ApObject containing an ApList under key \"components\" and you wanted to select it's first element, the selector would be \"detectedCode.components.0\" . To navigate nested objects/lists : Chain property names and indexes with a dot. For example, to select inputUnitCount from the nested estimatedCosts object, the selector is \"estimatedCosts.inputUnitCount\" . 3. Running a Standard Pipeline A standard pipeline runs a single workflow in the background. It's ideal for long-running or computationally intensive tasks because the API responds immediately, and you can check the results later. To run a standard pipeline, make a POST request to the /Pipelines endpoint with a JSON body containing your pipeline definition. Request Body Structure The request body must contain two properties: input : An ApScheme object that matches the input scheme of the first procedure in your pipeline. steps : An array of objects, where each object defines a pipeline step with a nodeId , a procedureId , and an optional outputValueSelector . Building the Request Following our example, let's create a pipeline that uses both procedures. First, define the steps array: \"steps\": [ { \"nodeId\": \"tire-ocr-ocr\", \"procedureId\": \"PerformSingleOcr\", \"outputValueSelector\": \"detectedCode\" }, { \"nodeId\": \"tire-ocr-postprocessing\", \"procedureId\": \"PerformTireCodePostprocessing\" } ] Notice the outputValueSelector in the first step, which ensures that only the detectedCode string is passed to the next procedure. Next, define the input for the first step. This must match the PerformSingleOcr procedure's expected input ApScheme. For the detectorType property, you may chose any of the supportedCases of the PerformSingleOcr scheme and add it to the value property of the enum. Let's assume you've already uploaded a tire image using the /Files/Upload endpoint, its ID is 16cf7a41-7ff8-492a-ab05-0ad0c724df75 and its content type image/jpeg . Put these values into the image property. Above: image used in this example Our input then would look like this: \"input\": { \"type\": \"ApObject\", \"properties\": { \"detectorType\": { \"type\": \"ApEnum\", \"value\": \"GoogleGemini\" }, \"image\": { \"type\": \"ApFile\", \"id\": \"16cf7a41-7ff8-492a-ab05-0ad0c724df75\", \"contentType\": \"image/jpeg\" } } } Combining these, you get the complete request body : { \"input\": { \"type\": \"ApObject\", \"properties\": { \"detectorType\": { \"type\": \"ApEnum\", \"value\": \"GoogleGemini\" }, \"image\": { \"type\": \"ApFile\", \"id\": \"16cf7a41-7ff8-492a-ab05-0ad0c724df75\", \"contentType\": \"image/jpeg\" } } }, \"steps\": [ { \"nodeId\": \"tire-ocr-ocr\", \"procedureId\": \"PerformSingleOcr\", \"outputValueSelector\": \"detectedCode\" }, { \"nodeId\": \"tire-ocr-postprocessing\", \"procedureId\": \"PerformTireCodePostprocessing\" } ] } The server will respond immediately with a pipelineId , which you can use to track the pipeline's progress. Analyzing Pipeline Results You can monitor the pipeline's status and retrieve the final results by calling the /PipelineResults/{pipelineId} endpoint. A pipeline is considered finished when the finishedAt property is no longer null. The result includes the full details of each step and any failure reasons. 4. Running an Awaited Pipeline An awaited pipeline runs a single workflow and waits for its completion before returning a response. This is useful for short-running tasks where you need the result immediately. To run an awaited pipeline, send a POST request to the /Pipelines/Awaited endpoint. The request body is the same as a standard pipeline, with one additional mandatory property: timeoutSeconds . This integer specifies how long the Orchestration Runner should wait for the pipeline to finish before returning a 408 - Timeout error . Example Request Body for an Awaited Pipeline : { \"input\": { ... }, \"steps\": [ ... ], \"timeoutSeconds\": 120 } If the pipeline completes successfully within the timeout, the server will return the complete pipeline result in the response body. If it times out, you can still retrieve the result later using the /PipelineResults/{pipelineId} endpoint. 5. Running a Pipeline Batch A pipeline batch runs the same pipeline on multiple inputs in parallel, making it ideal for processing large datasets. Batches cannot be awaited. To run a batch, send a POST request to the /Pipelines/Batch endpoint. Instead of a single input property, the request body uses an inputs array, where each element is an ApScheme object for a single pipeline run. The steps array remains the same. Example Request Body for a Pipeline Batch : { \"inputs\": [ { \"type\": \"ApObject\", \"properties\": { \"detectorType\": { \"type\": \"ApEnum\", \"value\": \"GoogleGemini\" }, \"image\": { \"type\": \"ApFile\", \"id\": \"16cf7a41-7ff8-492a-ab05-0ad0c724df75\", \"contentType\": \"image/jpeg\" } } }, { \"type\": \"ApObject\", \"properties\": { \"detectorType\": { \"type\": \"ApEnum\", \"value\": \"MistralPixtral\" }, \"image\": { \"type\": \"ApFile\", \"id\": \"63648f5b-fe9a-46df-90d3-d0b6ccf3345e\", \"contentType\": \"image/jpeg\" } } } ], \"steps\": [ { \"nodeId\": \"tire-ocr-ocr\", \"procedureId\": \"PerformSingleOcr\", \"outputValueSelector\": \"detectedCode\" }, { \"nodeId\": \"tire-ocr-postprocessing\", \"procedureId\": \"PerformTireCodePostprocessing\" } ] } The server will respond with a pipelineBatchId . Analyzing Pipeline Batch Results To analyze a batch, use the /PipelineResults/Batch/{pipelineBatchId} endpoint. The response will provide a summary of the batch's completion status, including the number of successful and failed pipelines, along with a list of each individual pipeline result.","title":"Running pipelines"},{"location":"running-pipelines/#running-pipelines","text":"A pipeline is a sequence of procedures from different nodes, where the output of one procedure serves as the input for the next. For a pipeline to run successfully, the ApSchemes of each chained procedure must be compatible. This means a procedure's output type must match the next procedure's expected input type.","title":"Running Pipelines"},{"location":"running-pipelines/#1-identifying-available-nodes-and-procedures","text":"Before building a pipeline, you need to know which nodes and procedures are available. You can get this information by calling the Orchestration Runner's /Nodes endpoint. The response is a JSON array of all available nodes and their procedures, including detailed ApScheme definitions for their inputs and outputs. Example Response from /Nodes { \"items\": [ { \"id\": \"tire-ocr-ocr\", \"procedures\": [ { \"id\": \"PerformSingleOcr\", \"schemaVersion\": 1, \"input\": { \"type\": \"ApObject\", \"properties\": { \"detectorType\": { \"type\": \"ApEnum\", \"value\": \"\", \"supportedCases\": [ \"GoogleGemini\", \"MistralPixtral\", \"OpenAiGpt\", \"GoogleCloudVision\", \"AzureAiVision\" ] }, \"image\": { \"type\": \"ApFile\", \"id\": \"00000000-0000-0000-0000-000000000000\", \"contentType\": \"\", \"supportedContentTypes\": [ \"image/jpeg\", \"image/png\", \"image/webp\" ] } }, \"nonRequiredProperties\": [] }, \"output\": { \"type\": \"ApObject\", \"properties\": { \"detectedCode\": { \"type\": \"ApString\", \"value\": \"\" }, \"estimatedCosts\": { \"type\": \"ApObject\", \"properties\": { \"inputUnitCount\": { \"type\": \"ApDecimal\", \"value\": 0 }, \"outputUnitCount\": { \"type\": \"ApDecimal\", \"value\": 0 }, \"billingUnit\": { \"type\": \"ApString\", \"value\": \"\" }, \"estimatedCost\": { \"type\": \"ApDecimal\", \"value\": 0 }, \"estimatedCostCurrency\": { \"type\": \"ApString\", \"value\": \"\" } }, \"nonRequiredProperties\": [] } }, \"nonRequiredProperties\": [\"estimatedCosts\"] } } ] }, { \"id\": \"tire-ocr-postprocessing\", \"procedures\": [ { \"id\": \"PerformTireCodePostprocessing\", \"schemaVersion\": 1, \"input\": { \"type\": \"ApString\", \"value\": \"\" }, \"output\": { \"type\": \"ApObject\", \"properties\": { \"rawCode\": { \"type\": \"ApString\", \"value\": \"\" }, \"postprocessedTireCode\": { \"type\": \"ApString\", \"value\": \"\" }, \"vehicleClass\": { \"type\": \"ApString\", \"value\": \"\" }, \"width\": { \"type\": \"ApDecimal\", \"value\": 0 }, \"aspectRatio\": { \"type\": \"ApDecimal\", \"value\": 0 }, \"construction\": { \"type\": \"ApString\", \"value\": \"\" }, \"diameter\": { \"type\": \"ApDecimal\", \"value\": 0 }, \"loadIndex\": { \"type\": \"ApString\", \"value\": \"\" }, \"speedRating\": { \"type\": \"ApString\", \"value\": \"\" } }, \"nonRequiredProperties\": [ \"vehicleClass\", \"width\", \"AspectRatio\", \"construction\", \"diameter\", \"loadIndex\", \"speedRating\" ] } } ] } ] } In this example, the tire-ocr-ocr node's PerformSingleOcr procedure outputs an ApObject that contains a detectedCode string. The tire-ocr-postprocessing node's PerformTireCodePostprocessing procedure expects a simple ApString as input. To chain these two, we must extract the detectedCode string from the first procedure's output object.","title":"1. Identifying Available Nodes and Procedures"},{"location":"running-pipelines/#2-output-value-selectors","text":"When a procedure's output scheme is more complex than the next procedure's input scheme, you can use an outputValueSelector to narrow down the output to a specific value. This ensures scheme compatibility and allows the pipeline to run. This selector is an optional parameter of each pipeline step when constructing a pipeline (more on that later). An outputValueSelector is a simple string that uses dot ( . ) separated identifiers to navigate the ApScheme JSON structure To select a property of ApObject : Use the property's name. For example, to select detectedCode from an ApObject, the selector is \"detectedCode\" . To select an item of ApList : Use the item's index. For example, if \"detectedCode\" was an ApObject containing an ApList under key \"components\" and you wanted to select it's first element, the selector would be \"detectedCode.components.0\" . To navigate nested objects/lists : Chain property names and indexes with a dot. For example, to select inputUnitCount from the nested estimatedCosts object, the selector is \"estimatedCosts.inputUnitCount\" .","title":"2. Output Value Selectors"},{"location":"running-pipelines/#3-running-a-standard-pipeline","text":"A standard pipeline runs a single workflow in the background. It's ideal for long-running or computationally intensive tasks because the API responds immediately, and you can check the results later. To run a standard pipeline, make a POST request to the /Pipelines endpoint with a JSON body containing your pipeline definition.","title":"3. Running a Standard Pipeline"},{"location":"running-pipelines/#request-body-structure","text":"The request body must contain two properties: input : An ApScheme object that matches the input scheme of the first procedure in your pipeline. steps : An array of objects, where each object defines a pipeline step with a nodeId , a procedureId , and an optional outputValueSelector .","title":"Request Body Structure"},{"location":"running-pipelines/#building-the-request","text":"Following our example, let's create a pipeline that uses both procedures. First, define the steps array: \"steps\": [ { \"nodeId\": \"tire-ocr-ocr\", \"procedureId\": \"PerformSingleOcr\", \"outputValueSelector\": \"detectedCode\" }, { \"nodeId\": \"tire-ocr-postprocessing\", \"procedureId\": \"PerformTireCodePostprocessing\" } ] Notice the outputValueSelector in the first step, which ensures that only the detectedCode string is passed to the next procedure. Next, define the input for the first step. This must match the PerformSingleOcr procedure's expected input ApScheme. For the detectorType property, you may chose any of the supportedCases of the PerformSingleOcr scheme and add it to the value property of the enum. Let's assume you've already uploaded a tire image using the /Files/Upload endpoint, its ID is 16cf7a41-7ff8-492a-ab05-0ad0c724df75 and its content type image/jpeg . Put these values into the image property. Above: image used in this example Our input then would look like this: \"input\": { \"type\": \"ApObject\", \"properties\": { \"detectorType\": { \"type\": \"ApEnum\", \"value\": \"GoogleGemini\" }, \"image\": { \"type\": \"ApFile\", \"id\": \"16cf7a41-7ff8-492a-ab05-0ad0c724df75\", \"contentType\": \"image/jpeg\" } } } Combining these, you get the complete request body : { \"input\": { \"type\": \"ApObject\", \"properties\": { \"detectorType\": { \"type\": \"ApEnum\", \"value\": \"GoogleGemini\" }, \"image\": { \"type\": \"ApFile\", \"id\": \"16cf7a41-7ff8-492a-ab05-0ad0c724df75\", \"contentType\": \"image/jpeg\" } } }, \"steps\": [ { \"nodeId\": \"tire-ocr-ocr\", \"procedureId\": \"PerformSingleOcr\", \"outputValueSelector\": \"detectedCode\" }, { \"nodeId\": \"tire-ocr-postprocessing\", \"procedureId\": \"PerformTireCodePostprocessing\" } ] } The server will respond immediately with a pipelineId , which you can use to track the pipeline's progress.","title":"Building the Request"},{"location":"running-pipelines/#analyzing-pipeline-results","text":"You can monitor the pipeline's status and retrieve the final results by calling the /PipelineResults/{pipelineId} endpoint. A pipeline is considered finished when the finishedAt property is no longer null. The result includes the full details of each step and any failure reasons.","title":"Analyzing Pipeline Results"},{"location":"running-pipelines/#4-running-an-awaited-pipeline","text":"An awaited pipeline runs a single workflow and waits for its completion before returning a response. This is useful for short-running tasks where you need the result immediately. To run an awaited pipeline, send a POST request to the /Pipelines/Awaited endpoint. The request body is the same as a standard pipeline, with one additional mandatory property: timeoutSeconds . This integer specifies how long the Orchestration Runner should wait for the pipeline to finish before returning a 408 - Timeout error . Example Request Body for an Awaited Pipeline : { \"input\": { ... }, \"steps\": [ ... ], \"timeoutSeconds\": 120 } If the pipeline completes successfully within the timeout, the server will return the complete pipeline result in the response body. If it times out, you can still retrieve the result later using the /PipelineResults/{pipelineId} endpoint.","title":"4. Running an Awaited Pipeline"},{"location":"running-pipelines/#5-running-a-pipeline-batch","text":"A pipeline batch runs the same pipeline on multiple inputs in parallel, making it ideal for processing large datasets. Batches cannot be awaited. To run a batch, send a POST request to the /Pipelines/Batch endpoint. Instead of a single input property, the request body uses an inputs array, where each element is an ApScheme object for a single pipeline run. The steps array remains the same. Example Request Body for a Pipeline Batch : { \"inputs\": [ { \"type\": \"ApObject\", \"properties\": { \"detectorType\": { \"type\": \"ApEnum\", \"value\": \"GoogleGemini\" }, \"image\": { \"type\": \"ApFile\", \"id\": \"16cf7a41-7ff8-492a-ab05-0ad0c724df75\", \"contentType\": \"image/jpeg\" } } }, { \"type\": \"ApObject\", \"properties\": { \"detectorType\": { \"type\": \"ApEnum\", \"value\": \"MistralPixtral\" }, \"image\": { \"type\": \"ApFile\", \"id\": \"63648f5b-fe9a-46df-90d3-d0b6ccf3345e\", \"contentType\": \"image/jpeg\" } } } ], \"steps\": [ { \"nodeId\": \"tire-ocr-ocr\", \"procedureId\": \"PerformSingleOcr\", \"outputValueSelector\": \"detectedCode\" }, { \"nodeId\": \"tire-ocr-postprocessing\", \"procedureId\": \"PerformTireCodePostprocessing\" } ] } The server will respond with a pipelineBatchId .","title":"5. Running a Pipeline Batch"},{"location":"running-pipelines/#analyzing-pipeline-batch-results","text":"To analyze a batch, use the /PipelineResults/Batch/{pipelineBatchId} endpoint. The response will provide a summary of the batch's completion status, including the number of successful and failed pipelines, along with a list of each individual pipeline result.","title":"Analyzing Pipeline Batch Results"}]}